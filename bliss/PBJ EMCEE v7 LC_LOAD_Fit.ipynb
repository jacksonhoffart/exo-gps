{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named emcee",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b7faa414e1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m  \u001b[0;31m# To play sound/music, esp. when notebook finishes running!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memcee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named emcee"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from IPython import display\n",
    "from IPython.display import Audio  # To play sound/music, esp. when notebook finishes running!\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import gc  # Garbage collection\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "pi = np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### FOR LOADING DATA TO RUN MCMC:\n",
    "\n",
    "my_mini_fcall = '10Se_10DDde_run10_'\n",
    "file_Name = 'Data_Info/' + my_mini_fcall  # Description of dataset to try reloading\n",
    "THE_input_N = 2160  # 2160\n",
    "THE_input_N_bin = 10  # 10\n",
    "yesdoP = False\n",
    "yesdoJ = False\n",
    "\n",
    "want_noisyM_key = False\n",
    "\n",
    "Brown_key = False\n",
    "brown_name = 'Data_Info/Brownnoise_run1_'  # Need to manually change run name with LC runs\n",
    "ratio_Brown_DelD = 1.0*np.ones(1)  # Extra brown noise to detector amplitude\n",
    "\n",
    "# # #\n",
    "all_NNI_key = False  # To only test NNI in the BLISS routine, a la Stevenson+2012 way for finding ideal mesh size\n",
    "# # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perf_astro_model(t_low,t_high,t_sing,astro,ecl):\n",
    "#     t_high,t_low = np.amax(t_sing),np.amin(t_sing)\n",
    "    a_mdl = (astro[0]*(-np.cos(t_sing*2.0*pi*astro[1]/(t_high - t_low) +\n",
    "                               astro[2])) + 1.0) # astro[]: 0 amp, 1 freq, 2 shift\n",
    "    occult = np.logical_and((ecl[0] - ecl[1])<=t_sing,t_sing<=(ecl[0] + ecl[1])) # ecl[]: 0 cent, 1 h-width, 2 depth\n",
    "    a_mdl[occult] -= ecl[2]\n",
    "    a_mdl[occult] = np.mean(a_mdl[occult])\n",
    "    return a_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perf_detect_model(x_o,y_o,dC_A,n_data):  # dC_A = detector Coefficient Array\n",
    "    d_mdl = np.polynomial.polynomial.polyval2d(x_o-15.0,y_o-15.0,dC_A)\n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  NO MORE!!!!!: Norm to sum = N, so mean d_mdl is near 1.0\n",
    "    return d_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-checking knots to position/extrapolate the noise grid correctly (on UNshifted centroids)\n",
    "def preNoi_binning(x_o,y_o,b_n):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    xy_C,x_edg,y_edg,viz = plt.hist2d(x_o,y_o,b_n,cmap=cm.viridis);\n",
    "    x_k = x_edg[1:] - 0.5*(x_edg[1:] - x_edg[0:-1])\n",
    "    y_k = y_edg[1:] - 0.5*(y_edg[1:] - y_edg[0:-1])\n",
    "    dx,dy = x_edg[1] - x_edg[0],y_edg[1] - y_edg[0]\n",
    "    \n",
    "    n_lx,n_hx = np.ceil((x_k[0] - 14.5)/dx),np.ceil((15.5 - x_k[-1])/dx)\n",
    "    n_ly,n_hy = np.ceil((y_k[0] - 14.5)/dy),np.ceil((15.5 - y_k[-1])/dy)  # How much more grid in each direction\n",
    "    v_lx,v_hx = x_k[0] - (n_lx*dx),x_k[-1] + (n_hx*dx)\n",
    "    v_ly,v_hy = y_k[0] - (n_ly*dy),y_k[-1] + (n_hy*dy)  # Values at grid edges\n",
    "    x_kTrap,y_kTrap = np.linspace(v_lx,v_hx,(b_n + n_lx + n_hx)),np.linspace(v_ly,v_hy,(b_n + n_ly + n_hy)) # New grid\n",
    "    \n",
    "    return y_kTrap,x_kTrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a map with small structure variations in it.\n",
    "def xtra_Dm_noise(x_o,y_o,dC_A,n_data,xpix,ypix,pixNoi):  # Have pre-sized pixNoi with preNoi_binning\n",
    "    d_mdl = perf_detect_model(x_o,y_o,dC_A,n_data)\n",
    "    highlow = np.amax(d_mdl) - np.amin(d_mdl)\n",
    "    \n",
    "#     # Original Pixelated Version\n",
    "#     F_ypix,F_xpix = np.transpose(np.tile(ypix,(n_data,1))),np.transpose(np.tile(xpix,(n_data,1)))\n",
    "#     i_ypix = np.argmin((y_o - F_ypix)**2.0,axis=0).astype(int)\n",
    "#     i_xpix = np.argmin((x_o - F_xpix)**2.0,axis=0).astype(int)\n",
    "    \n",
    "#     noize_mdl = 1.0*highlow*pixNoi[i_ypix,i_xpix]  # Staying with [y,x] ordering; Orig. 5% variation of Delta_D\n",
    "    \n",
    "    # New Spliny BLISS-like Version! Transpose puts input [y,x] into here needed [x,y]\n",
    "    noisy_spline = RectBivariateSpline(xpix,ypix,np.transpose(pixNoi),kx=2,ky=2)\n",
    "    \n",
    "    noize_mdl = 1000.0*highlow*noisy_spline(x_o,y_o,grid=False)  # 1000x means underlying poly. doesn't matter much\n",
    "    return (d_mdl + noize_mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LEGACY VERSION\n",
    "# def perf_detect_model(x_o,y_o,dCs,n_data):  # dCs = detector Coefficients\n",
    "#     d_mdl = (dCs[0]*((x_o-15.0)**2.0) + dCs[1]*((x_o-15.0)*(y_o-15.0)) + dCs[2]*((y_o-15.0)**2.0)\n",
    "#              + dCs[3]*(x_o-15.0) + dCs[4]*(y_o-15.0) + dCs[5])  # ALWAYS USE PARENTHESES AROUND BROKEN LINES!!!!!\n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  Norm to sum = N, so mean d_mdl is near 1.0\n",
    "#     return d_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_gen_model(n_data,t_low,t_high,astro,ecl,x_o,y_o,dC_A,mu_n,sig_n):\n",
    "    t = np.linspace(t_low,t_high,n_data)\n",
    "    a_mdl = perf_astro_model(t_low,t_high,t,astro,ecl)\n",
    "    d_mdl = perf_detect_model(x_o,y_o,dC_A,n_data)\n",
    "    y = a_mdl*d_mdl\n",
    "    y_data = y + (sig_n*np.random.randn(n_data) + mu_n)\n",
    "    return t,a_mdl,d_mdl,y,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternate, with map noise\n",
    "def real_gen_modelALT(n_data,xpix,ypix,pixNoi,t_low,t_high,astro,ecl,x_o,y_o,dC_A,mu_n,sig_n):\n",
    "    t = np.linspace(t_low,t_high,n_data)\n",
    "    a_mdl = perf_astro_model(t_low,t_high,t,astro,ecl)\n",
    "#     d_mdl = perf_detect_model(x_o,y_o,dC_A,n_data)\n",
    "    d_mdl = xtra_Dm_noise(x_o,y_o,dC_A,n_data,xpix,ypix,pixNoi)\n",
    "    y = a_mdl*d_mdl\n",
    "    y_data = y + (sig_n*np.random.randn(n_data) + mu_n)\n",
    "    return t,a_mdl,d_mdl,y,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Really Improved Version!\n",
    "def det_cof_limiter(order,x_pon,y_pon):\n",
    "    cof_mamp = 0.5  # Max amplitude of COMBINED non-offset terms at reference dist, relative to unity; tunable!\n",
    "    refer_dist = 0.1  # Reference distance on pixel to scale coeff (i.e. 0.5 is at edge, along center); tunable!\n",
    "    tot_C = int((order+2)*(order+1)/2) - 1  # Total C's needed; minus 1 because offset is now fixed\n",
    "    cof_l = -(cof_mamp/tot_C)*np.ones(tot_C+1)*(refer_dist**-(x_pon+y_pon))  # Last scales so all coeff...\n",
    "    cof_h = (cof_mamp/tot_C)*np.ones(cof_l.shape)*(refer_dist**-(x_pon+y_pon))  # ...CAN have similar mags\n",
    "    cof_l[order],cof_h[order] = 1,1  # Offset term: Now fixed to be 1.0\n",
    "    return cof_l,cof_h,tot_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ast_amp_limiter(t_low,t_high,t_ecl,freq,shift,d_ecl,s_weak):\n",
    "    ecl_divider = 1.0 - np.cos(t_ecl*2.0*pi*freq/(t_high - t_low) + shift)  # Trig term at eclipse: here [0,2]\n",
    "    amp_large = d_ecl/ecl_divider\n",
    "    amp_small = s_weak*amp_large\n",
    "    return amp_small,amp_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input (i.e. real) detector poly\n",
    "polyO_in = 7\n",
    "\n",
    "polyO_in = np.load(file_Name+'EMCEE_PBJ_polyOCn.npy')[0]\n",
    "\n",
    "temp_UTin_i = np.triu_indices(polyO_in+1)  # Including constant\n",
    "UTin_i = (temp_UTin_i[0],polyO_in - temp_UTin_i[1])  # Reflecting to upper-left triangular\n",
    "C_UTin = np.zeros((polyO_in+1,polyO_in+1))  # Blank coefficient array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output (i.e. fit) detector poly\n",
    "polyO_out = 2\n",
    "\n",
    "polyO_out = np.load(file_Name+'EMCEE_PBJ_polyOCn.npy')[2]\n",
    "\n",
    "temp_UTout_i = np.triu_indices(polyO_out+1)  # Ditto all\n",
    "UTout_i = (temp_UTout_i[0],polyO_out - temp_UTout_i[1])\n",
    "C_UTout = np.zeros((polyO_out+1,polyO_out+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Definitions for making more realistic centroids\n",
    "def projection_axes(thetaj,thetaw,thetasd,thetald):\n",
    "    return (np.cos(thetaj),np.sin(thetaj),\n",
    "            np.cos(thetaw),np.sin(thetaw),\n",
    "            np.cos(thetasd),np.sin(thetasd),\n",
    "            np.cos(thetald),np.sin(thetald))\n",
    "\n",
    "def reg_brown_mot(Abmx,Abmy,n_data):\n",
    "    bmx_steps = 2.0*np.random.random(n_data) - 1.0\n",
    "    bmx_steps[0] = 0  # To keep first step at selected x-position\n",
    "    time_bmx = np.cumsum(bmx_steps)\n",
    "    time_bmx = Abmx*time_bmx/np.amax(np.absolute(time_bmx))  # Rescale for maximum excursion\n",
    "    \n",
    "    bmy_steps = 2.0*np.random.random(n_data) - 1.0\n",
    "    bmy_steps[0] = 0  # Ditto for y-position\n",
    "    time_bmy = np.cumsum(bmy_steps)\n",
    "    time_bmy = Abmy*time_bmy/np.amax(np.absolute(time_bmy))\n",
    "    return time_bmx,time_bmy\n",
    "\n",
    "def wobble_amp_per_time(Aw,Pw,DAwmax,DPwmax,n_data):\n",
    "    amp_steps = 2.0*np.random.random(n_data) - 1.0\n",
    "    amp_steps[0] = 0  # To keep first step at selected amp\n",
    "    time_amps = np.cumsum(amp_steps)\n",
    "    time_amps = DAwmax*time_amps/np.amax(np.absolute(time_amps))  # Rescale for maximum excursion\n",
    "    time_amps += Aw\n",
    "    \n",
    "    per_steps = 2.0*np.random.random(n_data) - 1.0\n",
    "    per_steps[0] = 0  # Ditto for period\n",
    "    time_pers = np.cumsum(per_steps)\n",
    "    time_pers = DPwmax*time_pers/np.amax(np.absolute(time_pers))\n",
    "    time_pers += Pw\n",
    "    return time_amps,time_pers\n",
    "\n",
    "def telescope_pointing(J_full,W_full,Shtd_full,Ltd_full,t,t0,n_data):  # Jitter, Wobble, Short-, Long-Term Drift\n",
    "    # Unpacking Variables- see Ingalls+2016 Appendix A for details\n",
    "    Aj,Pj,phij,thetaj,Abmx,Abmy = J_full\n",
    "    Aw,Pw,phiw,Sw,DAwmax,DPwmax,thetaw = W_full\n",
    "    Asd,Psd,phisd,tausd,thetasd = Shtd_full\n",
    "    Ald,thetald = Ltd_full\n",
    "    tot_sec = t[-1] - t[0]\n",
    "    \n",
    "    # Projection Axes\n",
    "    c_thj,s_thj,c_thw,s_thw,c_thsd,s_thsd,c_thld,s_thld = projection_axes(thetaj,thetaw,thetasd,thetald)\n",
    "\n",
    "    ### Jitter\n",
    "    Jit_fun = Aj*np.sin((2.0*pi*(t-t0)/Pj) + phij)\n",
    "#     FBM_noise_x,FBM_noise_y = frac_brown_mot(Afbm,Beta,n_data,tot_sec)\n",
    "    RBM_noise_x,RBM_noise_y = reg_brown_mot(Abmx,Abmy,n_data)\n",
    "    Jit_x = Jit_fun*c_thj + RBM_noise_x\n",
    "    Jit_y = Jit_fun*s_thj + RBM_noise_y\n",
    "    ###\n",
    "    \n",
    "    ### Wobble\n",
    "    Awt,Pwt = wobble_amp_per_time(Aw,Pw,DAwmax,DPwmax,n_data)\n",
    "    small_q = ((t-t0)/Pwt) + (phiw/(2.0*pi))\n",
    "    wob_Low = np.logical_and(0 <= small_q,small_q < Sw)\n",
    "    wob_Mid = np.logical_and(Sw <= small_q,small_q < (1-Sw))\n",
    "    wob_Hig = np.logical_and((1-Sw) <= small_q,small_q < 1)\n",
    "    phiskt = np.zeros(n_data)\n",
    "    \n",
    "    phiskt[wob_Low] = pi*((1.0/(2.0*Sw)) - 2.0)*small_q[wob_Low]\n",
    "    phiskt[wob_Mid] = pi*(((small_q[wob_Mid] - Sw)/(1.0 - 2.0*Sw)) - 2.0*small_q[wob_Mid] + 0.5)\n",
    "    phiskt[wob_Hig] = pi*((1.0/(2.0*Sw)) - 2.0)*(small_q[wob_Hig] - 1.0)\n",
    "    \n",
    "    Wob_fun = Awt*np.sin(2.0*pi*small_q + phiskt)\n",
    "    Wob_x = Wob_fun*c_thw\n",
    "    Wob_y = Wob_fun*s_thw\n",
    "    ###\n",
    "    \n",
    "    ### Short-Term Drift- Since data is ~6 hours long can reasonably omit\n",
    "#     ShTD_fun = (Asd/np.sin(phisd))*np.sin((2.0*pi*(t-t0)/Psd) + phisd)*np.exp(-(t-t0)/tausd)\n",
    "#     ShTD_x = ShTD_fun*c_thsd\n",
    "#     ShTD_y = ShTD_fun*s_thsd\n",
    "    ShTD_x = 0\n",
    "    ShTD_y = 0\n",
    "    ###\n",
    "    \n",
    "    ### Long-Term Drift\n",
    "    LTD_fun = Ald*(t-t0)\n",
    "    LTD_x = LTD_fun*c_thld\n",
    "    LTD_y = LTD_fun*s_thld\n",
    "    ###\n",
    "    \n",
    "    ### Starting Centroid\n",
    "    initial_x = 0.6*np.random.random() + 15.0  # 15.0\n",
    "    initial_y = 0.6*np.random.random() + 15.0  # 15.0\n",
    "    ###\n",
    "    return initial_x+Jit_x+Wob_x+ShTD_x+LTD_x,initial_y+Jit_y+Wob_y+ShTD_y+LTD_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameters for generating centroids- see Ingalls+2016 Appendix A for details\n",
    "Jitter_vals = np.array([0.04,60,\n",
    "                 2.0*pi*np.random.random(),\n",
    "                 -45.0*pi/180.0,\n",
    "#                         0,\n",
    "#                         0])\n",
    "                        0.15*np.random.random() + 0.0375,\n",
    "                        0.15*np.random.random() + 0.0375])\n",
    "#                         0.2*np.random.random() + 0.05,\n",
    "#                         0.2*np.random.random() + 0.05])  # Last two are Reg. B.M., not Frac. B.M. anymore\n",
    "\n",
    "Wobble_vals = np.array([0.016*np.random.random() + 0.018,\n",
    "                 1600*np.random.random() + 1200,\n",
    "                 2.0*np.random.random() - 1.0,\n",
    "                 0.3*np.random.random() + 0.1,\n",
    "                 0.01,10.0,\n",
    "                 (-35.0*pi/180.0)*np.random.random() - (45.0*pi/180.0)])\n",
    "\n",
    "ShortDrift_vals = np.array([2.0*np.random.random() - 1.0,\n",
    "                 395.6,7.0*pi/4.0,\n",
    "                 np.absolute(1800*np.random.randn()),\n",
    "                 5.0*pi/9.0])\n",
    "\n",
    "LongDrift_vals = np.array([(0.0125/3600)*np.random.random(),\n",
    "                 (-40.0*pi/180.0)*np.random.random() - (55.0*pi/180.0)])\n",
    "\n",
    "# Jitter_vals = np.array([0.04,60,0.76*pi,-pi/4.0,0.15,0.15])\n",
    "# Wobble_vals = np.array([0.025,2000,-0.33,0.2,0.01,10.0,-pi/3.0])\n",
    "# ShortDrift_vals = np.array([0.5,395.6,7.0*pi/4.0,200,5.0*pi/9.0])\n",
    "# LongDrift_vals = np.array([0.0125/3600,-pi/3.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 2160  # 1800; Stick to even numbers from now on-- makes the FFT stuff simpler\n",
    "N = THE_input_N  # Just in case, setting as given at beginning\n",
    "\n",
    "l_t,h_t = 0.0,21600.0  # Seconds-- Ex) 21600 seconds (6 hrs) / ~3600 data points = ~6 seconds per datum\n",
    "t_point_reset = 0.0  # Sets initial time in telescope_pointing\n",
    "dummy_t = np.linspace(l_t,h_t,N)  # For telescope_pointing method\n",
    "\n",
    "e_hwidth_set = (h_t - l_t)/6.0  # Fixing h-width of eclipse (~tunable)\n",
    "within_ecl_N = N*(2.0*e_hwidth_set/(h_t - l_t))  # Data points inside eclipse\n",
    "\n",
    "### Tunable Eclipse Depth and (d_ecl/Delta D) Ratio\n",
    "ideal_eclipse_depth = 0.005*np.ones(1)  #*(1.0 + 0.01*np.random.randn(1))\n",
    "ratio_decl_DelD = 0.1*np.ones(1)  #*(1.0 + 0.01*np.random.randn(1))  # Eclipse depth / Detector amplitude\n",
    "ideal_Delta_D = ideal_eclipse_depth/ratio_decl_DelD  # Detector amplitude\n",
    "\n",
    "# SPLIT FOR THE MOMENT FROM BELOW, SO CENTROIDS CAN BE KEPT IF NEEDED.\n",
    "xNt_perf,yNt_perf = telescope_pointing(Jitter_vals,Wobble_vals,ShortDrift_vals,LongDrift_vals,\n",
    "                                      dummy_t,t_point_reset,N)\n",
    "xNt_perf = np.vsplit(np.load(file_Name+'EMCEE_PBJ_data.npy'),9)[7][0]\n",
    "yNt_perf = np.vsplit(np.load(file_Name+'EMCEE_PBJ_data.npy'),9)[8][0]\n",
    "\n",
    "Da,Db,Cn_in = det_cof_limiter(polyO_in,UTin_i[0],UTin_i[1])\n",
    "DCs_true = (Db-Da)*np.random.random(Cn_in+1) + Da  # [x^0----,x^1---,...,x^n]\n",
    "DCs_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[6:6+(Cn_in+1)]\n",
    "C_UTin[UTin_i] = DCs_true  # Actual input array\n",
    "\n",
    "# Master pixel noise grid\n",
    "if want_noisyM_key == True:\n",
    "    no_of_Kedge = 10\n",
    "    preK_Y,preK_X = preNoi_binning(xNt_perf,yNt_perf,no_of_Kedge)  # Where the noise grid should align\n",
    "    Master_pixNoi = np.random.randn(len(preK_Y),len(preK_X))\n",
    "    Master_pixNoi = np.load(file_Name+'EMCEE_PBJ_splinyMnoise.npy')\n",
    "    dummy_detect = xtra_Dm_noise(xNt_perf,yNt_perf,C_UTin,N,preK_X,preK_Y,Master_pixNoi)   #\n",
    "else:\n",
    "    dummy_detect = perf_detect_model(xNt_perf,yNt_perf,C_UTin,N)   #\n",
    "dummy_Delta_D = np.amax(dummy_detect) - np.amin(dummy_detect)  # Seeing detector amplitude\n",
    "rescale_D_factor = ideal_Delta_D/dummy_Delta_D  # Set rescaling factor\n",
    "\n",
    "nonoffset_mask = (np.indices(DCs_true.shape) != polyO_in)[0]\n",
    "DCs_true[nonoffset_mask] = rescale_D_factor*DCs_true[nonoffset_mask]  # Rescaling sens map coefficients\n",
    "DCs_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[6:6+(Cn_in+1)]  # Redoing, just in case\n",
    "C_UTin[UTin_i] = DCs_true  # Reassign coefficients to input array (for completeness)\n",
    "Da[nonoffset_mask] = rescale_D_factor*Da[nonoffset_mask]  #\n",
    "Db[nonoffset_mask] = rescale_D_factor*Db[nonoffset_mask]  # Rescale DCs limits (for making prior, below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More Tunable Parameter Ratios and Scales\n",
    "significance_decl = 50.0*np.ones(1)  #*(1.0 + 0.01*np.random.randn(1))  # Eclipse depth significance level\n",
    "scale_amp_weak = 0.7*np.ones(1)  #*(1.0 + 0.01*np.random.randn(1))  # Min astro amp, scaled from max: here (0,1]\n",
    "\n",
    "ratio_SigF_decl = (within_ecl_N**0.5)/significance_decl  # Photon noise / Eclipse depth == Sqrt[N_ecl] / Signif_ecl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ea_i = np.array([l_t + ((h_t - l_t)/3.0),e_hwidth_set])  # [cent,(h-width now set at 1/6 of observation)]\n",
    "Eb_i = np.array([h_t - ((h_t - l_t)/3.0),e_hwidth_set])\n",
    "Ecl_Ti = (Eb_i-Ea_i)*np.random.random(2) + Ea_i\n",
    "Ecl_Ti = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[3],\n",
    "                   np.load(file_Name+'EMCEE_PBJ_true.npy')[4]])  # Redundancy on loading (for good priors!)\n",
    "Ecl_Tii = ideal_eclipse_depth  # [depth]\n",
    "Ecl_Tii = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[5]])\n",
    "Ecl_true = np.concatenate((Ecl_Ti,Ecl_Tii))\n",
    "Ecl_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[3:6]\n",
    "\n",
    "Aa_ii = np.array([0.1])  # [freq]; Note starting with 'ii' set\n",
    "Ab_ii = np.array([0.4])\n",
    "Ast_Tii = (Ab_ii-Aa_ii)*np.random.random(1) + Aa_ii\n",
    "Ast_Tii = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[1]])\n",
    "Aa_iii,Ab_iii = np.array([pi*(1.0 - 2.0*Ast_Tii[0])]),np.array([pi])  # [shift]\n",
    "Ast_Tiii = (Ab_iii-Aa_iii)*np.random.random(1) + Aa_iii\n",
    "Ast_Tiii = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[2]])\n",
    "Aa_i,Ab_i = ast_amp_limiter(l_t,h_t,Ecl_Ti[0],Ast_Tii[0],Ast_Tiii,Ecl_Tii,scale_amp_weak)  # Now back to 'i' set\n",
    "Ast_Ti = (Ab_i-Aa_i)*np.random.random(1) + Aa_i  # [amp]\n",
    "Ast_Ti = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[0]])\n",
    "Ast_true = np.concatenate((Ast_Ti,Ast_Tii,Ast_Tiii))\n",
    "Ast_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[:3]\n",
    "\n",
    "mu_true = np.array([0.0])\n",
    "SigF_true = ratio_SigF_decl*Ecl_Tii  # Photon noise\n",
    "SigF_true = np.array([np.load(file_Name+'EMCEE_PBJ_true.npy')[-1]])\n",
    "\n",
    "if want_noisyM_key == True:\n",
    "    T,A_m,D_m,Y,Y_d = real_gen_modelALT(N,preK_X,preK_Y,Master_pixNoi,l_t,h_t,Ast_true,Ecl_true,xNt_perf,yNt_perf,\n",
    "                                        C_UTin,mu_true,SigF_true)  # DCs_true\n",
    "else:\n",
    "    T,A_m,D_m,Y,Y_d = real_gen_model(N,l_t,h_t,Ast_true,Ecl_true,xNt_perf,yNt_perf,C_UTin,mu_true,SigF_true)  # DCs_true\n",
    "\n",
    "rerun_flag = False  # To mark that this is the original run and not copy xNt,yNt yet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T,A_m,D_m,Y,Y_d,ig1,ig2,ig3,ig4 = np.vsplit(np.load(file_Name+'EMCEE_PBJ_data.npy'),9)  # ig = ignore!\n",
    "T,A_m,D_m,Y,Y_d = T[0],A_m[0],D_m[0],Y[0],Y_d[0]  # Since vsplit gives subarrays\n",
    "\n",
    "del ig1,ig2,ig3,ig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Where Brownian noise comes in because you want to keep the reloaded A(t) and D(t) the same!\n",
    "### Note that this means Y and Y_d change, but otherwise everything is identical.\n",
    "\n",
    "if Brown_key == False:\n",
    "    Bro_noi = 1.0 + np.zeros(N)  # Dummy signal\n",
    "elif Brown_key == True:  # Multiply on an extra noise signal!\n",
    "    Bro_noi,ig1 = reg_brown_mot(ratio_Brown_DelD*(np.amax(D_m) - np.amin(D_m)),ratio_Brown_DelD,N)\n",
    "    Bro_noi += 1.0  # +1.0 so mean is around unity (because of gen. model)\n",
    "    del ig1\n",
    "    Bro_noi = np.load(brown_name+'EMCEE_PBJ_brownsignal.npy')\n",
    "    \n",
    "    curr_rat = (np.amax(Bro_noi) - np.amin(Bro_noi))/(np.amax(D_m) - np.amin(D_m))\n",
    "    if (ratio_Brown_DelD[0]/curr_rat) > 1.0:  # Scaling signal as needed.\n",
    "        Bro_noi += ((ratio_Brown_DelD[0]/curr_rat) - 1.0)*(Bro_noi - np.mean(Bro_noi))\n",
    "    elif (ratio_Brown_DelD[0]/curr_rat) < 1.0:\n",
    "        Bro_noi -= ((1.0 - ratio_Brown_DelD[0]/curr_rat))*(Bro_noi - np.mean(Bro_noi))\n",
    "    Y = A_m*D_m*Bro_noi\n",
    "    Y_d = Y + (SigF_true*np.random.randn(N) + mu_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4.5))\n",
    "plt.plot(T,Y,'r',alpha=0.5)\n",
    "plt.plot(T,A_m*D_m,'b',alpha=0.5)\n",
    "plt.xlim([l_t,h_t]);\n",
    "plt.xlabel('$t$',size=30);\n",
    "plt.ylabel('$F(t)$',size=30);\n",
    "plt.title('Signal w/ & wo/ Extra Brownian Noise',size=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(T,Y_d,c='k',s=10)\n",
    "##\n",
    "# for i in np.linspace(0,N-1,N):\n",
    "#     plt.plot([T[i],T[i]],[Y_d[i]-SigF_true,Y_d[i]+SigF_true],c=(0,1,1),zorder=0)\n",
    "##\n",
    "plt.plot(T,Y,'r',lw=2)\n",
    "plt.plot(T,A_m,'g',lw=2,alpha=0.5)\n",
    "plt.xlim([l_t,h_t]);\n",
    "plt.xlabel('$t$',size=30);\n",
    "Yd_up,Yd_dw = np.amax(Y_d),np.amin(Y_d)\n",
    "Yd_scl = Yd_up - Yd_dw\n",
    "plt.ylim([Yd_dw - 0.1*Yd_scl,Yd_up + 0.1*Yd_scl])\n",
    "plt.ylabel('$F(t)$',size=30);\n",
    "plt.title('Flux Data w/ Full (& Astro) Mod.',size=30);\n",
    "# plt.figtext(0.92,0.5,r'$\\$_{e} = %.4f$' % significance_decl,size=30)\n",
    "plt.figtext(0.92,0.5,r'$\\$_{e} = ???$',size=30)\n",
    "plt.show()\n",
    "\n",
    "# SigF_true/Ecl_true[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(T,Y_d/D_m,c='k',alpha=0.25)\n",
    "plt.plot(T,A_m,'g',lw=2)\n",
    "plt.xlim([l_t,h_t]);\n",
    "plt.xlabel('$t$',size=30);\n",
    "Am_up,Am_dw = np.amax(A_m),np.amin(A_m)\n",
    "Am_scl = Am_up - Am_dw\n",
    "plt.ylim([Am_dw - 0.2*Am_scl,Am_up + 0.2*Am_scl])\n",
    "plt.ylabel('$A(t)$',size=30);\n",
    "plt.title('Astro Model (w/ Flux/Detector)',size=30);\n",
    "# plt.figtext(0.92,0.5,r'$\\frac{\\delta_{e}}{\\Delta D} = %.4f$' % ratio_decl_DelD,size=30)  # Inverse for paper(?)\n",
    "plt.figtext(0.92,0.5,r'$\\frac{\\delta_{e}}{\\Delta D} = ???$' % ratio_decl_DelD,size=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(T,Y_d/A_m,c='k',alpha=0.25)\n",
    "plt.plot(T,D_m,'m',lw=2)\n",
    "plt.xlim([l_t,h_t]);\n",
    "plt.xlabel('$t$',size=30);\n",
    "Dm_up,Dm_dw = np.amax(D_m),np.amin(D_m)\n",
    "Dm_scl = Dm_up - Dm_dw\n",
    "plt.ylim([Dm_dw - 0.2*Dm_scl,Dm_up + 0.2*Dm_scl])\n",
    "plt.ylabel('$F(t)/A(t)$',size=30);\n",
    "plt.title('Detector Residuals (w/ Flux/Astro)',size=30);\n",
    "plt.figtext(0.92,0.5,r'$\\Delta D = %.5f$' % ideal_Delta_D,size=30)\n",
    "plt.show()\n",
    "\n",
    "print('D(x0,y0) Mean = %.5f' % np.mean(D_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_bull,Y_bull = np.meshgrid(np.linspace(14.5,15.5,101),np.linspace(14.5,15.5,101))\n",
    "if want_noisyM_key == True:\n",
    "    FX_bull,FY_bull = np.ravel(X_bull),np.ravel(Y_bull)\n",
    "    FM_bull = xtra_Dm_noise(FX_bull,FY_bull,C_UTin,101*101,preK_X,preK_Y,Master_pixNoi)\n",
    "    M_bull = np.reshape(FM_bull,(101,101))\n",
    "else:\n",
    "    M_bull = perf_detect_model(X_bull,Y_bull,C_UTin,101*101)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "my_Smap = plt.contourf(X_bull,Y_bull,M_bull,100,cmap=cm.magma)\n",
    "plt.colorbar(my_Smap)\n",
    "plt.xticks([14.5,14.75,15.0,15.25,15.5])\n",
    "plt.yticks([14.5,14.75,15.0,15.25,15.5])\n",
    "plt.grid(True,which='major',color='white')\n",
    "plt.scatter(xNt_perf,yNt_perf,color=(1,1,1),s=3)\n",
    "plt.xlabel('$x_{0}$',size=30);\n",
    "plt.ylabel('$y_{0}$',size=30);\n",
    "plt.title('True Pixel Sens.',size=30);\n",
    "plt.xlim([14.5,15.5])\n",
    "plt.ylim([14.5,15.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gauss_key = False  # False uniform, True Gaussian\n",
    "# Cn_out = int((polyO_out+2)*(polyO_out+1)/2) - 1  # Fit C's needed; minus 1 because offset is now fixed\n",
    "out_Da,out_Db,Cn_out = det_cof_limiter(polyO_out,UTout_i[0],UTout_i[1])  # Out poly limits and Fit C's number\n",
    "out_nonoff_mask = (np.indices(out_Db.shape) != polyO_out)[0]\n",
    "linear_Cmax_ratio = out_Db[polyO_out-1]/Db[polyO_in-1]  # Out/In of max linear poly term\n",
    "\n",
    "cn_out_Vector = np.zeros(Cn_out+1)  # Output poly Cn holder\n",
    "cn_out_Vector[polyO_out] = 1.0  # Fix the offset term to 1.0\n",
    "\n",
    "### Astro, Eclipse, and Detector Coeff. priors\n",
    "if Gauss_key == False:\n",
    "    pri_AstEcl = np.array([[3.0*Ab_i[0],1.0,2.0*pi,h_t,(h_t - l_t),10.0*Ecl_Tii[0]],\n",
    "                           [0.1*Aa_i[0],0.001,0,l_t,0.0,0.0]])\n",
    "    \n",
    "    if linear_Cmax_ratio >= 2:  # i.e. Double the range that was possible after scaling the in_poly\n",
    "        pri_DCoeff = np.vstack((out_Db[out_nonoff_mask],out_Da[out_nonoff_mask]))\n",
    "    else:\n",
    "        pri_DCoeff = np.vstack((out_Db[out_nonoff_mask],out_Da[out_nonoff_mask]))*(1.0/linear_Cmax_ratio)\n",
    "        \n",
    "#     pri_DCoeff = np.array([[0.1],[-0.1]])*np.ones(Cn_out)  # [0.2,-0.2]; decrease?\n",
    "else:\n",
    "    pri_AstEcl = np.array([[0.5*(Ab_i[0]+Aa_i[0]),0.25,1.0,\n",
    "                            (h_t - l_t)/2.0,(h_t - l_t)/10.0,dummy_Delta_D],\n",
    "                           [5.0*(Ab_i[0]-Aa_i[0]),5.0,2.5,\n",
    "                            2.5*(h_t - l_t),(h_t - l_t),5.0*dummy_Delta_D]])\n",
    "    \n",
    "    if linear_Cmax_ratio >= 1:  # i.e. The range that was possible after scaling the in_poly\n",
    "        pri_DCoeff = np.vstack((np.zeros(Cn_out),5.0*out_Db[out_nonoff_mask]))\n",
    "    else:\n",
    "        pri_DCoeff = np.vstack((np.zeros(Cn_out),5.0*out_Db[out_nonoff_mask]))*(1.0/linear_Cmax_ratio)\n",
    "\n",
    "#     pri_DCoeff = np.array([[0.0],[1.0]])*np.ones(Cn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mvG_noise(sx,sy,rho,n_data):  # Multivariate Gaussian Noise\n",
    "    mu = np.array([0.0,0.0])\n",
    "    cov = np.array([[sx**2.0,rho*sx*sy],[rho*sx*sy,sy**2.0]])\n",
    "    D = np.random.multivariate_normal(mu,cov,n_data)\n",
    "    dx,dy = D[:,0],D[:,1]\n",
    "    return dx,dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noisy_key = True\n",
    "\n",
    "if rerun_flag == True:\n",
    "        storage_xNt,storage_yNt = xNt_vals,yNt_vals\n",
    "        storage_sigcent = np.array([sigx_cent,sigy_cent,rho_cent])  # [sx,sy,rho]\n",
    "\n",
    "sigx_cent = 0.01*(np.amax(xNt_perf) - np.amin(xNt_perf))\n",
    "sigy_cent = 0.01*(np.amax(yNt_perf) - np.amin(yNt_perf))\n",
    "rho_cent = np.random.random() - 0.5  # Takes values from -1.0 to 1.0, though probably don't use the extremes\n",
    "Cov_true = np.array([sigx_cent,sigy_cent,rho_cent])\n",
    "# Cov_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[-4:-1]\n",
    "if noisy_key == True:\n",
    "    # Adding \"noise\" to true xo and yo, now with covariance!\n",
    "    dxcent,dycent = mvG_noise(sigx_cent,sigy_cent,rho_cent,N)  \n",
    "    xNt_vals = xNt_perf + dxcent\n",
    "    yNt_vals = yNt_perf + dycent\n",
    "else:\n",
    "    xNt_vals = xNt_perf  # IF you wanna test the real values at some point...\n",
    "    yNt_vals = yNt_perf\n",
    "    \n",
    "rerun_flag = True  # Turning on the flag, in case you try second noisy centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ig1,ig2,ig3,ig4,ig5,xNt_vals,yNt_vals,ig6,ig7 = np.vsplit(np.load(file_Name+'EMCEE_PBJ_data.npy'),9)\n",
    "xNt_vals,yNt_vals = xNt_vals[0],yNt_vals[0]\n",
    "\n",
    "del ig1,ig2,ig3,ig4,ig5,ig6,ig7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Uncertainty and Covariance priors\n",
    "if Gauss_key == False:\n",
    "    pri_SigF = np.array([[10.0*SigF_true[0]],[0.0]])\n",
    "    pri_Cov = np.array([[100.0*sigx_cent,100.0*sigy_cent,1.0],[0.0,0.0,-1.0]])\n",
    "else:\n",
    "    pri_SigF = np.array([[(within_ecl_N**0.5)*Ecl_true[2]],[5.0*(within_ecl_N**0.5)*Ecl_true[2]]])  # Assume $_e = 1\n",
    "    pri_Cov = np.array([[10.0*sigx_cent,10.0*sigy_cent,0.0],[100.0*sigx_cent,100.0*sigy_cent,5.0]])\n",
    "#     pri_SigF = np.vstack((SigF_true,[0.01]))\n",
    "#     pri_Cov = np.vstack((Cov_true,[20.0*sigx_cent,20.0*sigy_cent,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BLISS-related definitions\n",
    "def lh_axes_binning(x_o,y_o,b_n,n_data):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    xy_C,x_edg,y_edg,viz = plt.hist2d(x_o,y_o,b_n,cmap=cm.viridis);\n",
    "    plt.title('Bin Counts',size=30)\n",
    "    plt.xlabel('$x_{0}$',size=30);\n",
    "    plt.ylabel('$y_{0}$',size=30);\n",
    "    plt.colorbar(viz)\n",
    "    x_k = x_edg[1:] - 0.5*(x_edg[1:] - x_edg[0:-1])\n",
    "    y_k = y_edg[1:] - 0.5*(y_edg[1:] - y_edg[0:-1])\n",
    "    x_Knt,y_Knt = np.meshgrid(x_k,y_k)\n",
    "    \n",
    "    l_b_x,h_b_x = lh_knot_ass(x_k,x_o,b_n,n_data)\n",
    "    l_b_y,h_b_y = lh_knot_ass(y_k,y_o,b_n,n_data)\n",
    "    \n",
    "    return l_b_x,h_b_x,l_b_y,h_b_y,x_k,y_k,xy_C,x_edg,y_edg,x_Knt,y_Knt  # Edges and Knot mesh included\n",
    "\n",
    "\n",
    "def lh_knot_ass(xy_k,xy_o,b_n,n_data):\n",
    "    bad_l_xy = (xy_o < xy_k[0])  # pre-finding points \"outside\" the knots\n",
    "    bad_h_xy = (xy_o > xy_k[-1]) \n",
    "    \n",
    "    mid_xy_cln = np.transpose(np.tile(xy_k,(n_data,1)))\n",
    "    diff_xy_cln = xy_o - mid_xy_cln\n",
    "    diff_xy_cln[diff_xy_cln < 0] = (xy_k[-1] - xy_k[0])\n",
    "    l_b_xy = np.argmin(diff_xy_cln**2.0,axis=0)\n",
    "    \n",
    "    diff_xy_cln = mid_xy_cln - xy_o\n",
    "    diff_xy_cln[diff_xy_cln < 0] = (xy_k[-1] - xy_k[0])\n",
    "    h_b_xy = np.argmin(diff_xy_cln**2.0,axis=0)\n",
    "    \n",
    "    l_b_xy[l_b_xy == b_n-1] = b_n-2  # tuning l_b_xy upper bound and vice versa\n",
    "    h_b_xy[h_b_xy == 0] = 1\n",
    "    h_b_xy[h_b_xy == l_b_xy] += 1  # Avoiding same bin reference (PROBLEMS?)\n",
    "    \n",
    "    l_b_xy[bad_l_xy] = 0  # manually extrapolating points \"outside\" the knots\n",
    "    h_b_xy[bad_l_xy] = 1\n",
    "    l_b_xy[bad_h_xy] = b_n-2\n",
    "    h_b_xy[bad_h_xy] = b_n-1\n",
    "    \n",
    "    return l_b_xy,h_b_xy\n",
    "\n",
    "\n",
    "def which_NNI(xy_Ct,l_b_x,h_b_x,l_b_y,h_b_y):\n",
    "    bad_left = np.logical_or(xy_Ct[l_b_y,l_b_x] == 0.1,xy_Ct[l_b_y,h_b_x] == 0.1)\n",
    "    bad_right = np.logical_or(xy_Ct[h_b_y,l_b_x] == 0.1,xy_Ct[h_b_y,h_b_x] == 0.1)\n",
    "    nni_mask = np.logical_or(bad_left,bad_right)\n",
    "    if all_NNI_key == True:\n",
    "        nni_mask = np.ones(nni_mask.shape).astype(bool)\n",
    "    return nni_mask,np.logical_not(nni_mask)\n",
    "\n",
    "\n",
    "def lh_bin_to_knot(x_k,y_k,l_b_x,h_b_x,l_b_y,h_b_y):\n",
    "    l_x_K = x_k[l_b_x]  # Index arrays are awesome!\n",
    "    h_x_K = x_k[h_b_x]\n",
    "    l_y_K = y_k[l_b_y]\n",
    "    h_y_K = y_k[h_b_y]\n",
    "    return l_x_K,h_x_K,l_y_K,h_y_K\n",
    "\n",
    "\n",
    "def bound_knot(x_o,y_o,l_b_x,h_b_x,l_b_y,h_b_y,l_x_K,h_x_K,l_y_K,h_y_K,n_data):\n",
    "    left = (x_o - l_x_K <= h_x_K - x_o)\n",
    "    right = np.logical_not(left)\n",
    "    bottom = (y_o - l_y_K <= h_y_K - y_o)\n",
    "    top = np.logical_not(bottom)\n",
    "    \n",
    "    xo_B_i,yo_B_i = np.zeros(n_data),np.zeros(n_data)\n",
    "    xo_B_i[left] = l_b_x[left]\n",
    "    xo_B_i[right] = h_b_x[right]\n",
    "    yo_B_i[bottom] = l_b_y[bottom]\n",
    "    yo_B_i[top] = h_b_y[top]\n",
    "    \n",
    "    return xo_B_i.astype(int),yo_B_i.astype(int)\n",
    "\n",
    "\n",
    "def bliss_dist(x_o,y_o,l_x_K,h_x_K,l_y_K,h_y_K):\n",
    "    LLd = (h_x_K - x_o)*(h_y_K - y_o)\n",
    "    LRd = (x_o - l_x_K)*(h_y_K - y_o)\n",
    "    ULd = (h_x_K - x_o)*(y_o - l_y_K)\n",
    "    URd = (x_o - l_x_K)*(y_o - l_y_K)\n",
    "    return LLd,LRd,ULd,URd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Pre-computing D(xo,yo) associations\n",
    "N_bin = 10\n",
    "N_bin = THE_input_N_bin  # Again, just in case, setting from the value at the top\n",
    "\n",
    "low_bx,high_bx,low_by,high_by,x_Knots,y_Knots,BK_T,xEdg,yEdg,xKmesh,yKmesh = lh_axes_binning(xNt_vals,yNt_vals,N_bin,N)\n",
    "BK_T[BK_T == 0] = 0.1  # Avoid division errors; BK_T = BoundKnot_Tally\n",
    "\n",
    "tBK_T = np.transpose(BK_T)  # Since BK_T has [x,y] ordering and we want [y,x] for visualizing + consistency\n",
    "\n",
    "NNI,BLS = which_NNI(tBK_T,low_bx,high_bx,low_by,high_by)  # Data mask for both methods\n",
    "delta_xo,delta_yo = x_Knots[1] - x_Knots[0],y_Knots[1] - y_Knots[0]\n",
    "\n",
    "low_Kx,high_Kx,low_Ky,high_Ky = lh_bin_to_knot(x_Knots,y_Knots,low_bx,high_bx,low_by,high_by)\n",
    "xNt_B_i,yNt_B_i = bound_knot(xNt_vals,yNt_vals,low_bx,high_bx,low_by,high_by,low_Kx,high_Kx,low_Ky,high_Ky,N)\n",
    "LL_dst,LR_dst,UL_dst,UR_dst = bliss_dist(xNt_vals,yNt_vals,low_Kx,high_Kx,low_Ky,high_Ky)\n",
    "\n",
    "Dxy_Full = np.zeros((N,N_bin,N_bin))\n",
    "Dxy_Solo = np.zeros((N_bin,N_bin))\n",
    "Dxy_i = np.linspace(0,N-1,N).astype(int)\n",
    "\n",
    "flux_bliss = np.zeros(N)\n",
    "\n",
    "xNt_B_lin = xNt_B_i + (N_bin*yNt_B_i)  # Linear indexing for faster 'np.bincount' routine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### For full MCMC: jumping in ALL knot parameters\n",
    "mask_goodBKT = (BK_T != 0.1)\n",
    "tmask_goodBKT = (tBK_T != 0.1)  # The important version for [y,x] consistency\n",
    "tot_goodK = len(tBK_T[tmask_goodBKT])\n",
    "\n",
    "# \"True\" detector values for theta, using knots computed with centroid noise.\n",
    "Kfl_true = perf_detect_model(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],C_UTin,tot_goodK)  # DCs_true\n",
    "# Kfl_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[6+(Cn_in+1)+Cn_out:-4]\n",
    "\n",
    "print('N/K = %.2f' % (N/tot_goodK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Knot Values prior\n",
    "if Gauss_key == False:\n",
    "    pri_Knots = np.array([[np.amax(Y_d)],[np.amin(Y_d)]])*np.ones((2,tot_goodK))  # [[2.0*np.amax(Kfl_true)],[0.0]]\n",
    "else:\n",
    "    pri_Knots = np.array([[np.mean(Kfl_true)],[15.0*np.std(Kfl_true)]])*np.ones((2,tot_goodK))\n",
    "#     pri_Knots = np.vstack((Kfl_true,3.0*np.std(Kfl_true)*np.ones(tot_goodK)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_bounds = [x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]]\n",
    "\n",
    "def style_maps():\n",
    "    plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "    plt.xticks(xEdg,rotation=45,visible=False)\n",
    "    plt.setp(plt.gca().get_xticklabels()[::5],visible=True)\n",
    "    plt.yticks(yEdg,visible=False)\n",
    "    plt.setp(plt.gca().get_yticklabels()[::5],visible=True)\n",
    "    plt.grid(True,which='major')\n",
    "    plt.xlabel('$x_{0}$',size=30);\n",
    "    plt.ylabel('$y_{0}$',size=30);\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.subplot(121)\n",
    "# plt.scatter(xNt_vals[BLS],yNt_vals[BLS],color=(0,0,1))\n",
    "# plt.scatter(xNt_vals[NNI],yNt_vals[NNI],color=(0,0,0.4))\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color='0.7',marker='x')\n",
    "# plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],color='k',marker='x',s=50)\n",
    "# plt.title('Centroid Groups',size=30);\n",
    "# # plt.legend(('BLISS','NNI'),bbox_to_anchor=(1.3,0.8))\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.scatter(xNt_vals[BLS],yNt_vals[BLS],color=(0,0,1))\n",
    "# plt.scatter(xNt_vals[NNI],yNt_vals[NNI],color=(0,0,0.4))\n",
    "# plt.xticks([14.5,14.75,15.0,15.25,15.5])\n",
    "# plt.yticks([14.5,14.75,15.0,15.25,15.5])\n",
    "# plt.grid(True,which='major')\n",
    "# plt.scatter(xKmesh,yKmesh,color='0.7',marker='x',alpha=0.25)\n",
    "# plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],color='k',marker='x',s=50,alpha=0.25)\n",
    "# plt.xlabel('$x_{0}$',size=30);\n",
    "# plt.ylabel('$y_{0}$',size=30);\n",
    "# plt.title('Pixel Scale',size=30);\n",
    "# plt.legend(('BLISS','NNI'),bbox_to_anchor=(1.3,0.8))\n",
    "# plt.xlim([14.5,15.5])\n",
    "# plt.ylim([14.5,15.5])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,6))\n",
    "# plt.scatter(xNt_perf,yNt_perf,color=(1,0.5,0),marker='o',alpha=0.75)\n",
    "# plt.scatter(xNt_vals,yNt_vals,color=(0,0,0.75),marker='o',alpha=0.75)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color='0.7',marker='x')\n",
    "# plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],color='k',marker='x',s=50)\n",
    "# plt.title('Centroid Deviations',size=30);\n",
    "# plt.legend(('Perfect Centroids','Measured Centroids'),bbox_to_anchor=(1.5,0.8))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Faster 'B'-type flux summation using 'np.bincount' (learned while dealing with slow covariance functions) \n",
    "def map_flux_avgQuick(data,ast,dxyi_lin):\n",
    "    dxy_map = ((np.bincount(dxyi_lin,weights=data/ast,\n",
    "                            minlength=(N_bin*N_bin)).reshape((N_bin,N_bin)))/tBK_T)  # Avg flux at each data knot\n",
    "    return dxy_map  # Using [y,x] for consistency\n",
    "\n",
    "# Note use of 'minlength': you'd often get output that's too short otherwise! (i.e. not EVERY possible knot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Legacy 'B'-type flux summation\n",
    "def map_flux_avg(data,ast,dxy_cln,dxy_ind):\n",
    "#     dxy_cln[dxy_ind,yNt_B_i,xNt_B_i] = 0  # Probably unnecessary?\n",
    "    dxy_cln[dxy_ind,yNt_B_i,xNt_B_i] = data/ast   # Using [y,x] for consistency\n",
    "    dxy_map = np.sum(dxy_cln,axis=0)/tBK_T  # Avg flux at each data knot\n",
    "    return dxy_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_flux_jumped(dxy_sing,theta_K):\n",
    "#     dxy_sing[tmask_goodBKT] = 0  # Probably unnecessary?\n",
    "    dxy_sing[tmask_goodBKT] = theta_K  # Using \"tmask_goodBKT\" for consistency\n",
    "    return dxy_sing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### Comparing Sensitivity Maps\n",
    "# fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "# F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "# minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "# maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.subplot(221)\n",
    "# m_B_map = plt.imshow(fB_avg,interpolation='hermite',origin='lower',\n",
    "#                      extent=[x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]],\n",
    "#                      cmap=cm.magma,vmin=minviz,vmax=maxviz)\n",
    "# plt.colorbar(m_B_map)\n",
    "# coverup = plt.imshow(tmask_goodBKT,origin='lower',extent=ext_bounds,\n",
    "#                   cmap=cm.gray,vmin=0.25,vmax=0.75)\n",
    "# coverup.cmap.set_under(color='0.95',alpha=1)\n",
    "# coverup.cmap.set_over(alpha=0)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh[fB_avg > maxviz],yKmesh[fB_avg > maxviz],color=(1,0,0),marker='.')\n",
    "# plt.scatter(xKmesh[np.logical_and(fB_avg < minviz,fB_avg > 0)],\n",
    "#             yKmesh[np.logical_and(fB_avg < minviz,fB_avg > 0)],color=(0,1,1),marker='.')\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('BLISS Map $\\sigma_{F}$',size=30)\n",
    "\n",
    "# plt.subplot(222)\n",
    "# PJ_range = maxviz - minviz\n",
    "# m_PJ_map = plt.imshow(F_avg,interpolation='hermite',origin='lower',\n",
    "#                      extent=[x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]],\n",
    "#                      cmap=cm.magma,vmin=minviz,vmax=maxviz)\n",
    "# plt.colorbar(m_PJ_map)\n",
    "# coverup = plt.imshow(tmask_goodBKT,origin='lower',extent=ext_bounds,\n",
    "#                   cmap=cm.gray,vmin=0.25,vmax=0.75)\n",
    "# coverup.cmap.set_under(color='0.95',alpha=1)\n",
    "# coverup.cmap.set_over(alpha=0)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('Real (P @ Knots)',size=30)\n",
    "\n",
    "# plt.subplot(223)\n",
    "# # B_PJdiff = (fB_avg - F_avg)/PJ_range\n",
    "# # B_PJdiff = (fB_avg - F_avg)/SigF_true\n",
    "# B_PJdiff = (fB_avg - F_avg)*(tBK_T**0.5)/SigF_true\n",
    "# # B_PJdiff = ((N/tot_goodK)**0.5)*(fB_avg - F_avg)/SigF_true\n",
    "# # B_PJdiff = (fB_avg - F_avg)*(within_ecl_N**0.5)/SigF_true  # 5/13/16: Nick sugg. (off Kevin) compare discrep to sig_photon in-eclipse.\n",
    "# limviz = np.amax(np.absolute(B_PJdiff[tmask_goodBKT]))\n",
    "# B_PJdiff[tmask_goodBKT == False] = np.nan  # So bad knots fall outside the color range.\n",
    "# B_PJmap = plt.imshow(B_PJdiff,interpolation='hermite',origin='lower',\n",
    "#            extent=ext_bounds,cmap=cm.BrBG_r,vmin=(-limviz),vmax=limviz)\n",
    "# plt.colorbar(B_PJmap)\n",
    "# B_PJmap.cmap.set_bad(color='k',alpha=1.0)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('(B - Real)/$\\sigma$',size=30)\n",
    "\n",
    "# plt.subplot(224)\n",
    "# B_PJmap2 = plt.imshow(B_PJdiff,interpolation='hermite',origin='lower',\n",
    "#            extent=ext_bounds,cmap=cm.coolwarm,vmin=-3,vmax=3)\n",
    "# plt.colorbar(B_PJmap2)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('$\\leftarrow$ Unity Scale',size=30)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # New correct normalization by number of knots- duh! (Thanks Kevin)\n",
    "# print('(B - Re)/sigma_noise values')\n",
    "# this_wavg = np.sum(B_PJdiff[tmask_goodBKT]*tBK_T[tmask_goodBKT])/N\n",
    "# print('Mean = %.3f' % this_wavg)\n",
    "# this_wvarA = np.sum(((B_PJdiff[tmask_goodBKT] - this_wavg)**2.0)*tBK_T[tmask_goodBKT])\n",
    "# this_wvarB = N/((N**2.0) - np.sum(tBK_T[tmask_goodBKT]**2.0))\n",
    "# this_wstd = (this_wvarA*this_wvarB)**0.5\n",
    "# print('STD = %.3f' % this_wstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('Reg. Mean = %.3f' % (np.mean(B_PJdiff[tmask_goodBKT])))\n",
    "# print('Reg. STD = %.3f' % (np.std(B_PJdiff[tmask_goodBKT])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# %matplotlib inline\n",
    "# %matplotlib osx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "# F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "# minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "# maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "\n",
    "# # star_colrs = np.zeros((tot_goodK,4))\n",
    "# # star_colrs[:,:3] = np.array([0,0.75,1])\n",
    "# star_colrs = tBK_T[tmask_goodBKT]  # [:,3]  /np.amax(tBK_T[tmask_goodBKT])\n",
    "\n",
    "# secs_in_hr = 3600.0\n",
    "# plt.figure(figsize=(12,6))\n",
    "\n",
    "# plt.subplot2grid((2,5),(0,0),rowspan=1,colspan=2)\n",
    "# # plt.subplot(131)\n",
    "# plt.plot(T/secs_in_hr,xNt_vals,'0.25',lw=0.5)\n",
    "# plt.xlim([l_t/secs_in_hr,h_t/secs_in_hr]);\n",
    "# # plt.xlabel('Time (hrs)',size='x-large');\n",
    "# plt.gca().set_xticklabels([])\n",
    "# plt.ylabel('Centroid x',size='x-large');\n",
    "# plt.ylim([np.amin(xNt_vals)-0.025,0.025+np.amax(xNt_vals)])\n",
    "# plt.locator_params(axis='y',nbins=5)\n",
    "# # good_Xs = plt.gca().get_yticks()\n",
    "# # plt.title('Flux Data w/ Full (& Astro) Mod.',size=30);\n",
    "\n",
    "# plt.subplot2grid((2,5),(1,0),rowspan=1,colspan=2)\n",
    "# # plt.subplot(132)\n",
    "# plt.plot(T/secs_in_hr,yNt_vals,'0.25',lw=0.5)\n",
    "# plt.xlim([l_t/secs_in_hr,h_t/secs_in_hr]);\n",
    "# plt.xlabel('Time (hrs)',size='x-large');\n",
    "# # plt.gca().set_xticklabels([])\n",
    "# plt.ylabel('Centroid y',size='x-large');\n",
    "# plt.ylim([np.amin(yNt_vals)-0.025,0.025+np.amax(yNt_vals)])\n",
    "# plt.locator_params(axis='y',nbins=5)\n",
    "# # good_Ys = plt.gca().get_yticks()\n",
    "# # plt.title('Flux Data w/ Full (& Astro) Mod.',size=30);\n",
    "\n",
    "# plt.subplot2grid((2,5),(0,2),rowspan=2,colspan=3)\n",
    "# # plt.subplot(133)\n",
    "# plt.scatter(xNt_vals,yNt_vals,color=(0,0,0),alpha=0.2,s=10,marker='.')\n",
    "# # plt.scatter(xNt_vals[BLS],yNt_vals[BLS],color=(0,0,0),alpha=0.25,s=10,marker='.')\n",
    "# # plt.scatter(xNt_vals[NNI],yNt_vals[NNI],color=(0.5,0,0),alpha=0.25,s=10,marker='.')\n",
    "# plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "# # plt.xticks([])\n",
    "# plt.xlabel('Pixel x',size='x-large');\n",
    "# plt.ylabel('Pixel y',size='x-large');\n",
    "# # plt.title('True Sensitivity',size='large')\n",
    "# plt.xlim([x_Knots[0] - 0.5*delta_xo,x_Knots[-1] + 0.5*delta_xo])\n",
    "# plt.ylim([y_Knots[0] - 0.5*delta_yo,y_Knots[-1] + 0.5*delta_yo])\n",
    "# plt.locator_params(axis='x',nbins=8)\n",
    "# plt.locator_params(axis='y',nbins=8)\n",
    "# my_stars = plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],c=star_colrs,cmap=cm.Blues,\n",
    "#             edgecolor='k',marker='*',s=250,vmin=0)  # (0,0.75,1)\n",
    "# plt.colorbar(my_stars,label='Linked Centroids',shrink=1.0)\n",
    "# plt.scatter(xKmesh[tmask_goodBKT == False],yKmesh[tmask_goodBKT == False],color=(1,0.75,0.75),\n",
    "#             marker='x',s=50)  #,alpha=0.25)  # (0,0.375,0.5)\n",
    "# plt.legend(('Centroids','Good Knots','Bad Knots'),loc='lower left',bbox_to_anchor=(0.025,0.025),\n",
    "#            fontsize='small',fancybox=True)  # loc='lower right',bbox_to_anchor=(0.975,0.025)\n",
    "\n",
    "# plt.tight_layout(w_pad=3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "mynewmap_ind = np.ravel(np.transpose(np.tile(np.linspace(0,N_bin-1,N_bin).astype(int),(N_bin,1))))\n",
    "newmap_xxi,newmap_yyi = np.meshgrid(mynewmap_ind,mynewmap_ind)\n",
    "newmap_badmask = (tmask_goodBKT[newmap_yyi,newmap_xxi] == False)\n",
    "\n",
    "Smap_bounds = [np.amin(xNt_perf),np.amax(xNt_perf),np.amin(yNt_perf),np.amax(yNt_perf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "# minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "# maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "minviz = np.amin(D_m)\n",
    "maxviz = np.amax(D_m)\n",
    "\n",
    "# star_colrs = np.zeros((tot_goodK,4))\n",
    "# star_colrs[:,:3] = np.array([0,0.75,1])\n",
    "star_colrs = tBK_T[tmask_goodBKT]  # [:,3]  /np.amax(tBK_T[tmask_goodBKT])\n",
    "\n",
    "# easy_tic = np.linspace(0.990,1.010,21)\n",
    "easy_tic = np.linspace(0.95,1.05,11)\n",
    "\n",
    "secs_in_hr = 3600.0\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot2grid((2,5),(0,0),rowspan=1,colspan=2)\n",
    "# plt.subplot(131)\n",
    "plt.plot(T/secs_in_hr,xNt_perf,'0.25',lw=0.5)\n",
    "plt.xlim([l_t/secs_in_hr,h_t/secs_in_hr]);\n",
    "# plt.xlabel('Time (hrs)',size='x-large');\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.ylabel('Centroid x',size='x-large');\n",
    "plt.ylim([np.amin(xNt_perf)-0.025,0.025+np.amax(xNt_perf)])\n",
    "plt.locator_params(axis='y',nbins=5)\n",
    "# good_Xs = plt.gca().get_yticks()\n",
    "# plt.title('Flux Data w/ Full (& Astro) Mod.',size=30);\n",
    "\n",
    "plt.subplot2grid((2,5),(1,0),rowspan=1,colspan=2)\n",
    "# plt.subplot(132)\n",
    "plt.plot(T/secs_in_hr,yNt_perf,'0.25',lw=0.5)\n",
    "plt.xlim([l_t/secs_in_hr,h_t/secs_in_hr]);\n",
    "plt.xlabel('Time (hr)',size='x-large');\n",
    "# plt.gca().set_xticklabels([])\n",
    "plt.ylabel('Centroid y',size='x-large');\n",
    "plt.ylim([np.amin(yNt_perf)-0.025,0.025+np.amax(yNt_perf)])\n",
    "plt.locator_params(axis='y',nbins=5)\n",
    "# good_Ys = plt.gca().get_yticks()\n",
    "# plt.title('Flux Data w/ Full (& Astro) Mod.',size=30);\n",
    "\n",
    "plt.subplot2grid((2,5),(0,2),rowspan=2,colspan=3)\n",
    "# plt.subplot(133)\n",
    "plt.scatter(xNt_perf,yNt_perf,color=(0,0,0),alpha=0.1,s=3,marker='.')\n",
    "\n",
    "X_bull,Y_bull = np.meshgrid(np.linspace(np.amin(xNt_perf),np.amax(xNt_perf),int(N_bin**2)),\n",
    "                            np.linspace(np.amin(yNt_perf),np.amax(yNt_perf),int(N_bin**2)))\n",
    "M_bull = perf_detect_model(X_bull,Y_bull,C_UTin,int(N_bin**4))\n",
    "M_bull[newmap_badmask] = np.nan\n",
    "\n",
    "my_Smap = plt.imshow(M_bull,interpolation='hermite',origin='lower',\n",
    "           extent=Smap_bounds,cmap=cm.viridis,vmin=minviz,vmax=maxviz)\n",
    "# my_Smap.cmap.set_bad(color='k',alpha=0.02)\n",
    "# my_Smap.cmap.set_over(color='r',alpha=1.0)\n",
    "# my_Smap.cmap.set_under(color='c',alpha=1.0)\n",
    "Smap_bar = plt.colorbar(my_Smap,ticks=easy_tic,label='Sensitivity',extend='both',shrink=1.0)\n",
    "Smap_bar.formatter.set_useOffset(False)\n",
    "Smap_bar.update_ticks()\n",
    "\n",
    "plt.gca().set_aspect((np.amax(xNt_perf)-np.amin(xNt_perf))/(np.amax(yNt_perf)-np.amin(yNt_perf)))\n",
    "# plt.xticks([])\n",
    "plt.xlabel('Pixel x',size='x-large');\n",
    "plt.ylabel('Pixel y',size='x-large');\n",
    "# plt.title('Pixel Sensitivity',size='large')\n",
    "plt.xlim([np.amin(xNt_perf),np.amax(xNt_perf)])\n",
    "plt.ylim([np.amin(yNt_perf),np.amax(yNt_perf)])\n",
    "plt.locator_params(axis='x',nbins=8)\n",
    "plt.locator_params(axis='y',nbins=8)\n",
    "\n",
    "plt.tight_layout(w_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "# F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "# minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "# maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "\n",
    "# # plt.figure(figsize=(12,6))\n",
    "# plt.figure(figsize=(6,6))\n",
    "\n",
    "# # plt.subplot2grid((2,6),(0,2),rowspan=2,colspan=2)\n",
    "# # plt.subplot(121)\n",
    "# easy_tic = np.linspace(0.990,1.010,21)\n",
    "# extra_F_avg = F_avg\n",
    "# extra_F_avg[tmask_goodBKT == False] = np.nan\n",
    "# PJ_range = maxviz - minviz\n",
    "# m_PJ_map = plt.imshow(extra_F_avg,interpolation='hermite',origin='lower',\n",
    "#                       extent=[x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]],\n",
    "#                       cmap=cm.magma,vmin=minviz,vmax=maxviz)\n",
    "# my_tr_bar = plt.colorbar(m_PJ_map,ticks=easy_tic,label='Sensitivity',shrink=0.75)\n",
    "# my_tr_bar.formatter.set_useOffset(False)  # Taking away offset\n",
    "# my_tr_bar.update_ticks()\n",
    "# plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "# # plt.xticks([])\n",
    "# plt.xlabel('Pixel x',size='x-large');\n",
    "# plt.ylabel('Pixel y',size='x-large');\n",
    "# # plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# # plt.title('True Map',size='large')\n",
    "# plt.title('True Map',size='large')\n",
    "# plt.locator_params(axis='x',nbins=6)\n",
    "# plt.locator_params(axis='y',nbins=6)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "\n",
    "# # plt.subplot2grid((2,6),(0,4),rowspan=2,colspan=2)\n",
    "# # plt.subplot(122)\n",
    "# # B_PJdiff = (fB_avg - F_avg)/PJ_range\n",
    "# # B_PJdiff = (fB_avg - F_avg)/SigF_true\n",
    "# B_PJdiff = (fB_avg - F_avg)*(tBK_T**0.5)/SigF_true\n",
    "# # B_PJdiff = ((N/tot_goodK)**0.5)*(fB_avg - F_avg)/SigF_true\n",
    "# # B_PJdiff = (fB_avg - F_avg)*(within_ecl_N**0.5)/SigF_true  # 5/13/16: Nick sugg. (off Kevin) compare discrep to sig_photon in-eclipse.\n",
    "# B_PJdiff[tmask_goodBKT == False] = np.nan  # So bad knots fall outside the color range.\n",
    "\n",
    "# B_PJmap2 = plt.imshow(B_PJdiff,interpolation='hermite',origin='lower',\n",
    "#            extent=ext_bounds,cmap=cm.coolwarm,vmin=-3.0,vmax=3.0)\n",
    "# # B_PJmap2.cmap.set_bad(color='w',alpha=1.0)\n",
    "# plt.colorbar(B_PJmap2,extend='both',ticks=np.linspace(-3.0,3.0,7),label=r'(BLISS - True) / Photon Noise',shrink=0.75)\n",
    "# plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "# plt.xlabel('Pixel x',size='x-large');\n",
    "# plt.ylabel('Pixel y',size='x-large');\n",
    "# # plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('BLISS vs True Map',size='large')\n",
    "# plt.locator_params(axis='x',nbins=6)\n",
    "# plt.locator_params(axis='y',nbins=6)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # plt.tight_layout(w_pad=3)\n",
    "# plt.show()\n",
    "\n",
    "# ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.amax(B_PJdiff[tmask_goodBKT]),np.amin(B_PJdiff[tmask_goodBKT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "\n",
    "# star_colrs = np.zeros((tot_goodK,4))\n",
    "# star_colrs[:,:3] = np.array([0,0.75,1])\n",
    "star_colrs = tBK_T[tmask_goodBKT]  # [:,3]  /np.amax(tBK_T[tmask_goodBKT])\n",
    "\n",
    "secs_in_hr = 3600.0\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# plt.subplot2grid((2,5),(0,2),rowspan=2,colspan=3)\n",
    "plt.subplot(121)\n",
    "plt.scatter(xNt_vals,yNt_vals,color=(0,0,0),alpha=0.2,s=2,marker='.')  # s=10\n",
    "# plt.scatter(xNt_vals[BLS],yNt_vals[BLS],color=(0,0,0),alpha=0.25,s=10,marker='.')\n",
    "# plt.scatter(xNt_vals[NNI],yNt_vals[NNI],color=(0.5,0,0),alpha=0.25,s=10,marker='.')\n",
    "plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "# plt.xticks([])\n",
    "plt.xlabel('Pixel x',size='x-large');\n",
    "plt.ylabel('Pixel y',size='x-large');\n",
    "plt.title('Knot Mesh',size='large')\n",
    "plt.xlim([x_Knots[0] - 0.5*delta_xo,x_Knots[-1] + 0.5*delta_xo])\n",
    "plt.ylim([y_Knots[0] - 0.5*delta_yo,y_Knots[-1] + 0.5*delta_yo])\n",
    "plt.locator_params(axis='x',nbins=8)\n",
    "plt.locator_params(axis='y',nbins=8)\n",
    "my_stars = plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],c=star_colrs,cmap=cm.Purples,\n",
    "            edgecolor='k',marker='*',s=175,vmin=1)  # (0,0.75,1), s=250\n",
    "plt.colorbar(my_stars,label='Linked Centroids',shrink=0.75)\n",
    "plt.scatter(xKmesh[tmask_goodBKT == False],yKmesh[tmask_goodBKT == False],color=(1,0.75,0.75),\n",
    "            marker='x',s=35)  #,alpha=0.25)  # (0,0.375,0.5), s=50\n",
    "legend = plt.legend(('Centroids','Good Knots','Bad Knots'),loc='lower right',bbox_to_anchor=(0.975,0.025),\n",
    "           fontsize='small',fancybox=True)  # loc='lower right',bbox_to_anchor=(0.975,0.025)\n",
    "legend.legendHandles[1].set_color(cm.Purples(0.67)[:3])\n",
    "legend.legendHandles[1].set_edgecolor('black')\n",
    "\n",
    "# plt.subplot2grid((2,6),(0,4),rowspan=2,colspan=2)\n",
    "plt.subplot(122)\n",
    "# B_PJdiff = (fB_avg - F_avg)/PJ_range\n",
    "# B_PJdiff = (fB_avg - F_avg)/SigF_true\n",
    "B_PJdiff = (fB_avg - F_avg)*(tBK_T**0.5)/SigF_true\n",
    "# B_PJdiff = ((N/tot_goodK)**0.5)*(fB_avg - F_avg)/SigF_true\n",
    "# B_PJdiff = (fB_avg - F_avg)*(within_ecl_N**0.5)/SigF_true  # 5/13/16: Nick sugg. (off Kevin) compare discrep to sig_photon in-eclipse.\n",
    "B_PJdiff[tmask_goodBKT == False] = np.nan  # So bad knots fall outside the color range.\n",
    "\n",
    "B_PJmap2 = plt.imshow(B_PJdiff,interpolation='hermite',origin='lower',\n",
    "           extent=ext_bounds,cmap=cm.coolwarm,vmin=-3.0,vmax=3.0)\n",
    "# B_PJmap2.cmap.set_bad(color='w',alpha=1.0)\n",
    "plt.colorbar(B_PJmap2,extend='neither',ticks=np.linspace(-3.0,3.0,7),\n",
    "             label=r'(BLISS - True) / Photon Noise per Bin',shrink=0.75)  # neither' just for this plot\n",
    "plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "plt.xlabel('Pixel x',size='x-large');\n",
    "plt.ylabel('Pixel y',size='x-large');\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "plt.title('BLISS vs True Knots',size='large')\n",
    "# plt.xlim([x_Knots[0] - 0.5*delta_xo,x_Knots[-1] + 0.5*delta_xo])\n",
    "# plt.ylim([y_Knots[0] - 0.5*delta_yo,y_Knots[-1] + 0.5*delta_yo])\n",
    "plt.locator_params(axis='x',nbins=8)\n",
    "plt.locator_params(axis='y',nbins=8)\n",
    "\n",
    "plt.tight_layout(w_pad=3)\n",
    "plt.show()\n",
    "\n",
    "# New correct normalization by number of knots- duh! (Thanks Kevin)\n",
    "print('(B - Re)/sigma_noise values')\n",
    "this_wavg = np.sum(B_PJdiff[tmask_goodBKT]*tBK_T[tmask_goodBKT])/N\n",
    "print('Mean = %.3f' % this_wavg)\n",
    "this_wvarA = np.sum(((B_PJdiff[tmask_goodBKT] - this_wavg)**2.0)*tBK_T[tmask_goodBKT])\n",
    "this_wvarB = N/((N**2.0) - np.sum(tBK_T[tmask_goodBKT]**2.0))\n",
    "this_wstd = (this_wvarA*this_wvarB)**0.5\n",
    "print('STD = %.3f' % this_wstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Pre-computing Flux Evaluation Items\n",
    "f_binax = 1  # Number of probability eval points along each axis in a bin; '1' FOR SAFETY RIGHT NOW!!!\n",
    "evl_x = np.linspace(xEdg[0] + delta_xo/(2*f_binax),xEdg[-1] - delta_xo/(2*f_binax),N_bin*f_binax)\n",
    "evl_y = np.linspace(yEdg[0] + delta_yo/(2*f_binax),yEdg[-1] - delta_yo/(2*f_binax),N_bin*f_binax)\n",
    "xEmesh,yEmesh = np.meshgrid(evl_x,evl_y)\n",
    "xEmesh_n = np.transpose(np.tile(xEmesh,(N,1,1)),axes=(1,2,0))\n",
    "yEmesh_n = np.transpose(np.tile(yEmesh,(N,1,1)),axes=(1,2,0))\n",
    "delta_ex,delta_ey = evl_x[1] - evl_x[0],evl_y[1] - evl_y[0]\n",
    "\n",
    "Ki_Evl = np.ravel(np.transpose(np.tile(np.linspace(0,N_bin-1,N_bin),(f_binax,1)))).astype(int)\n",
    "xi_EtoK,yi_EtoK = np.meshgrid(Ki_Evl,Ki_Evl)\n",
    "\n",
    "xi_Kstn,yi_Kstn = np.meshgrid(np.linspace(0,N_bin-1,N_bin).astype(int),np.linspace(0,N_bin-1,N_bin).astype(int))\n",
    "xi_Kstn_e = np.transpose(np.tile(xi_Kstn,(N_bin*f_binax,N_bin*f_binax,1,1)),axes=(2,3,0,1))\n",
    "yi_Kstn_e = np.transpose(np.tile(yi_Kstn,(N_bin*f_binax,N_bin*f_binax,1,1)),axes=(2,3,0,1))\n",
    "\n",
    "mask_EtoK = np.logical_and(xi_EtoK == xi_Kstn_e,yi_EtoK == yi_Kstn_e)\n",
    "mask_EtoK_n = np.transpose(np.tile(mask_EtoK,(N,1,1,1,1)),axes=(1,2,3,4,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,6))\n",
    "# style_maps()\n",
    "# plt.scatter(xEmesh,yEmesh,color=(0,1,1),marker='*')\n",
    "# plt.scatter(xKmesh,yKmesh,color='0.7',marker='x')\n",
    "# plt.scatter(xKmesh[tmask_goodBKT],yKmesh[tmask_goodBKT],color='k',marker='x',s=50)\n",
    "# plt.scatter(xNt_vals,yNt_vals,color=(0,0,0.75),marker='o',alpha=0.2)\n",
    "# plt.title('Evaluation Grid',size=30)\n",
    "# plt.legend(('Eval. Points','Knots','Good Knots','Data'),bbox_to_anchor=(1.4,0.8))\n",
    "# plt.xlim([xEdg[0] - 0.5*(xEdg[1] - xEdg[0]),xEdg[-1] + 0.5*(xEdg[1] - xEdg[0])])\n",
    "# plt.ylim([yEdg[0] - 0.5*(yEdg[1] - yEdg[0]),yEdg[-1] + 0.5*(yEdg[1] - yEdg[0])])  # Had to add this for some reason...\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def biv_normal(x_n,y_n,mx,my,sx,sy,rho):\n",
    "    con = 1.0/(2.0*pi*sx*sy*((1 - rho**2.0)**0.5))\n",
    "    xterm,yterm,xy_term = ((x_n - mx)/sx)**2.0,((y_n - my)/sy)**2.0,(2.0*rho*(x_n - mx)*(y_n - my))/(sx*sy)\n",
    "    pcon = 1.0/(2*(1 - rho**2.0))\n",
    "    return con*np.exp(-pcon*(xterm + yterm - xy_term))*delta_ex*delta_ey  # Had missed the -xy before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit biv_normal(xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Method to include centroid uncertainties on \"B\"-type runs\n",
    "def map_flux_eval(data,ast,M_etok,x_n,y_n,mx,my,sx,sy,rho):\n",
    "    probxy_evl = biv_normal(x_n,y_n,mx,my,sx,sy,rho)  # [N_evl,N_evl,N]\n",
    "    raw_map = np.sum(np.sum(probxy_evl,axis=2)*M_etok,axis=(2,3))  # Converting above into [N_bin,N_bin]\n",
    "    flux_map = np.sum(np.sum((data/ast)*probxy_evl,axis=2)*M_etok,axis=(2,3))  # Ditto\n",
    "    dxy_map = flux_map/raw_map  # Of course: flux-weighted, instead of tBK_T dividing!\n",
    "    dxy_map[tmask_goodBKT == False] = 0.0  # Zeroing out bad knots (not BLISS'ed yet)\n",
    "    return dxy_map\n",
    "\n",
    "# Note how you multiply by a mask (logical operator) for the maps --> Useful trick sometimes to keep dimensionality!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# diffuse_flux = map_flux_eval(Y_d,A_m,mask_EtoK,xEmesh_n,yEmesh_n,\n",
    "#                              xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent)\n",
    "# minvizE = np.amin(diffuse_flux[tmask_goodBKT])\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# f_E_map = plt.imshow(diffuse_flux,interpolation='hermite',origin='lower',\n",
    "#            extent=[x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]],cmap=cm.magma,vmin=minvizE)\n",
    "# plt.colorbar(f_E_map)\n",
    "# # f_E_map.cmap.set_bad(color='k',alpha=0.25)\n",
    "# coverup2 = plt.imshow(tmask_goodBKT,origin='lower',extent=ext_bounds,\n",
    "#                   cmap=cm.gray,vmin=0.25,vmax=0.75)\n",
    "# coverup2.cmap.set_under(color='0.95',alpha=1)\n",
    "# coverup2.cmap.set_over(alpha=0)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('EVAL Map',size=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # BEdiff = (diffuse_flux - F_avg)/PJ_range\n",
    "# BEdiff = (diffuse_flux - F_avg)/SigF_true\n",
    "# limvizE = np.amax(np.absolute(BEdiff))\n",
    "# BEdiff[tmask_goodBKT == False] = np.nan  # So bad knots fall outside the color range.\n",
    "\n",
    "# plt.figure(figsize=(6,6))\n",
    "# BE_map = plt.imshow(BEdiff,interpolation='hermite',origin='lower',\n",
    "#            extent=ext_bounds,cmap=cm.coolwarm,vmin=(-limvizE),vmax=limvizE)\n",
    "# plt.colorbar(BE_map)\n",
    "# BE_map.cmap.set_bad(color='k',alpha=1.0)\n",
    "# style_maps()\n",
    "# plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "# plt.title('(EV - Real)/$\\sigma$',size=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Method to include centroid uncertainties on \"P\"-type runs\n",
    "def sigxy_detect_model(dC_A,x_n,y_n,mx,my,sx,sy,rho,n_data):  # dCs = detector Coefficients\n",
    "    xe,ye = x_n[:,:,0],y_n[:,:,0]  # Making [N_evl,N_evl]\n",
    "    d_alone = np.polynomial.polynomial.polyval2d(xe-15.0,ye-15.0,dC_A)\n",
    "    probxy_evl = np.transpose(biv_normal(x_n,y_n,mx,my,sx,sy,rho),axes=(2,0,1)) # Making [N,N_evl,N_evl]\n",
    "    d_mdl = d_alone*probxy_evl\n",
    "    d_mdl = np.sum(d_mdl,axis=(1,2))\n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  Norm to sum = N, so mean d_mdl is near 1.0\n",
    "    return d_mdl  # Slow because of all the evaluations!\n",
    "\n",
    "# EXAMPLE: sigxy_detect_model(C_UTin,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit sigxy_detect_model(C_UTin,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_goodEvl = np.any(np.transpose(mask_EtoK,axes=(2,3,0,1))*tmask_goodBKT,axis=(2,3))\n",
    "xoE,yoE = xEmesh[mask_goodEvl],yEmesh[mask_goodEvl]\n",
    "N_usedE = len(xoE)\n",
    "\n",
    "low_bxE,high_bxE = lh_knot_ass(x_Knots,xoE,N_bin,N_usedE)\n",
    "low_byE,high_byE = lh_knot_ass(y_Knots,yoE,N_bin,N_usedE)\n",
    "NNI_E,BLS_E = which_NNI(tBK_T,low_bxE,high_bxE,low_byE,high_byE)\n",
    "\n",
    "low_KxE,high_KxE,low_KyE,high_KyE = lh_bin_to_knot(x_Knots,y_Knots,low_bxE,high_bxE,low_byE,high_byE)\n",
    "xoE_B_i,yoE_B_i = xi_EtoK[mask_goodEvl],yi_EtoK[mask_goodEvl]\n",
    "LL_dstE,LR_dstE,UL_dstE,UR_dstE = bliss_dist(xoE,yoE,low_KxE,high_KxE,low_KyE,high_KyE)\n",
    "\n",
    "f_bliss_Egrid = np.zeros(xEmesh.shape)\n",
    "f_bliss_Evect = np.zeros(N_usedE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def secondary_bliss(evl_grid,b_flux,dxy_map,x_o,y_o):\n",
    "    LL = dxy_map[low_byE,low_bxE]*LL_dstE  # Using [y,x] for consistency\n",
    "    LR = dxy_map[high_byE,low_bxE]*LR_dstE\n",
    "    UL = dxy_map[low_byE,high_bxE]*UL_dstE\n",
    "    UR = dxy_map[high_byE,high_bxE]*UR_dstE\n",
    "    b_flux[BLS_E] = (LL[BLS_E] + LR[BLS_E] + UL[BLS_E] + UR[BLS_E])/(delta_xo*delta_yo)  # BLISS points\n",
    "    b_flux[NNI_E] = dxy_map[yoE_B_i[NNI_E],xoE_B_i[NNI_E]]  # Nearest Neighbor points\n",
    "    evl_grid[mask_goodEvl] = b_flux  # Converting to [N_evl,N_evl]\n",
    "    return evl_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Method to include centroid uncertainties on \"J\"-type runs (and maybe \"B\"-type, too)\n",
    "def sigxy_eval_map(dxy_sing,theta_K,evl_grid,b_flux,x_o,y_o,x_n,y_n,mx,my,sx,sy,rho,n_data):\n",
    "    dxy_map = map_flux_jumped(dxy_sing,theta_K)  # [N_bin,N_bin]\n",
    "    f_evl_sqr = secondary_bliss(evl_grid,b_flux,dxy_map,x_o,y_o)  # [N_evl,N_evl]\n",
    "    probxy_evl = np.transpose(biv_normal(x_n,y_n,mx,my,sx,sy,rho),axes=(2,0,1)) # [N,N_evl,N_evl]\n",
    "    d_mdl = f_evl_sqr*probxy_evl  # Sens. at eval points * Prob. of seeing each data point there\n",
    "    d_mdl = np.sum(d_mdl,axis=(1,2))  # Collapse to N-length detector model!\n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  Norm to sum = N, so mean d_mdl is near 1.0\n",
    "    return d_mdl\n",
    "\n",
    "# Example: sigxy_eval_map(Dxy_Solo,Kfl_true,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,\n",
    "#                xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bliss_meth(n_data,b_flux,dxy_map,x_o,y_o):  # # GOOD VERSION!!!!!!!!!!!\n",
    "#     b_flux[:] = 0  # Probably unnecessary?\n",
    "    LL = dxy_map[low_by,low_bx]*LL_dst  # Using [y,x] for consistency\n",
    "    LR = dxy_map[low_by,high_bx]*LR_dst\n",
    "    UL = dxy_map[high_by,low_bx]*UL_dst\n",
    "    UR = dxy_map[high_by,high_bx]*UR_dst\n",
    "    b_flux[BLS] = (LL[BLS] + LR[BLS] + UL[BLS] + UR[BLS])/(delta_xo*delta_yo)  # BLISS points\n",
    "    b_flux[NNI] = dxy_map[yNt_B_i[NNI],xNt_B_i[NNI]]  # Nearest Neighbor points\n",
    "#     b_flux = n_data*b_flux/np.sum(b_flux)  # Normalizing as above\n",
    "    return b_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Better Covariance Methods\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Setting up [Ne,Ne,N] index arrays\n",
    "Ne_yi,Ne_xi = np.indices((N_bin*f_binax,N_bin*f_binax))\n",
    "Ne_xi_N = np.transpose(np.tile(Ne_xi,(N,1,1)),axes=(1,2,0))\n",
    "Ne_yi_N = np.transpose(np.tile(Ne_yi,(N,1,1)),axes=(1,2,0))\n",
    "\n",
    "x_near_Ei = np.argmin((xNt_vals - np.transpose(np.tile(evl_x,(N,1))))**2.0,axis=0)\n",
    "y_near_Ei = np.argmin((yNt_vals - np.transpose(np.tile(evl_y,(N,1))))**2.0,axis=0)\n",
    "x_near_E = evl_x[x_near_Ei]\n",
    "y_near_E = evl_y[y_near_Ei] # Getting eval points closest to each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Creating \"nearest selected\" evaluation points to include for each centroid\n",
    "evl_range = 2\n",
    "select_mapEvl = (np.absolute(x_near_Ei - Ne_xi_N) <= evl_range)*(np.absolute(y_near_Ei - Ne_yi_N) <= evl_range)\n",
    "select_mapEvl = np.transpose(np.transpose(select_mapEvl,axes=(2,0,1))*mask_goodEvl,axes=(1,2,0))\n",
    "\n",
    "xNt_n = np.tile(xNt_vals,(N_bin*f_binax,N_bin*f_binax,1))\n",
    "yNt_n = np.tile(yNt_vals,(N_bin*f_binax,N_bin*f_binax,1))\n",
    "\n",
    "xNt_E,yNt_E = xNt_n[select_mapEvl],yNt_n[select_mapEvl]  # Condensed 1D centroid location arrays\n",
    "xMesh_nE,yMesh_nE = xEmesh_n[select_mapEvl],yEmesh_n[select_mapEvl]  # Condensed 1D eval point arrays\n",
    "\n",
    "blank_EvlN = np.zeros(Ne_yi_N.shape)  # For using in tighter biv_N function and similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look_p = 190\n",
    "# plt.imshow(select_mapEvl[:,:,look_p],origin='bottom')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scl_fct = 1.0\n",
    "# S_x,S_y,R_xy = scl_fct*sigx_cent,scl_fct*sigy_cent,rho_cent\n",
    "# look_p = 90\n",
    "\n",
    "# plt.contourf(xEmesh,yEmesh,biv_normal(xEmesh,yEmesh,xNt_vals[look_p],yNt_vals[look_p],S_x,S_y,R_xy),\n",
    "#              50,cmap=cm.inferno)\n",
    "# plt.scatter(xEmesh[select_mapEvl[:,:,look_p]],yEmesh[select_mapEvl[:,:,look_p]],color='c',alpha=0.25)\n",
    "# plt.scatter(x_near_E[look_p],y_near_E[look_p],color='g',s=50,alpha=0.75)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bivN_tight(blnkD,x_ne,y_ne,mux_e,muy_e,sx,sy,rho):\n",
    "    con = 1.0/(2.0*pi*sx*sy*((1 - rho**2.0)**0.5))\n",
    "    xtrm,ytrm,xytrm = ((x_ne - mux_e)/sx)**2.0,((y_ne - muy_e)/sy)**2.0,(2.0*rho*(x_ne - mux_e)*(y_ne - muy_e))/(sx*sy)\n",
    "    pcon = 1.0/(2.0*(1 - rho**2.0))\n",
    "    blnkD[select_mapEvl] = con*np.exp(-pcon*(xtrm + ytrm - xytrm))*delta_ex*delta_ey\n",
    "    return blnkD\n",
    "\n",
    "# Example: bivN_tight(blank_EvlN,xMesh_nE,yMesh_nE,xNt_E,yNt_E,sigx_cent,sigy_cent,rho_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Creating 1D index array of EXPLICIT data+knots (i.e. each data point has unique knot index)\n",
    "eN_I = np.tile(np.linspace(0,N-1,N),(N_bin*f_binax,N_bin*f_binax,1)).astype(int)\n",
    "xi_EtoK_N = np.transpose(np.tile(xi_EtoK,(N,1,1)),axes=(1,2,0))\n",
    "yi_EtoK_N = np.transpose(np.tile(yi_EtoK,(N,1,1)),axes=(1,2,0))\n",
    "\n",
    "oneD_Klist = np.ravel(xi_EtoK_N + N_bin*yi_EtoK_N + (N_bin*N_bin)*eN_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1D index arrays for faster Eval into Knots summation\n",
    "S_sx,S_sy,S_rho = 25,25,19  # 50,50,19\n",
    "btm_sx,top_sx = 0.2*sigx_cent,10.0*sigx_cent  # sy and sx with *sig here, instead?\n",
    "btm_sy,top_sy = 0.2*sigy_cent,10.0*sigy_cent\n",
    "btm_rho,top_rho = -0.9,0.9\n",
    "\n",
    "rho_A,sy_A,sx_A = np.meshgrid(np.linspace(btm_rho,top_rho,S_rho),np.linspace(btm_sy,top_sy,S_sy),\n",
    "                              np.linspace(btm_sx,top_sx,S_sx),indexing='ij')\n",
    "rho_AF,sy_AF,sx_AF = np.ravel(rho_A),np.ravel(sy_A),np.ravel(sx_A)\n",
    "\n",
    "rho_I,sy_I,sx_I = np.indices((S_rho,S_sy,S_sx))\n",
    "rho_IF,sy_IF,sx_IF = np.ravel(rho_I),np.ravel(sy_I),np.ravel(sx_I)\n",
    "\n",
    "tempo_DProb = np.zeros((S_rho,S_sy,S_sx,N,N_bin,N_bin)) # [rho,sigy,sigx,N,y,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HOLY CRAP, THE 'np.bincount' FUNCTION IS F@@@ING AWESOME!!!\n",
    "def covar_preRunner(blnkD,x_ne,y_ne,mux_e,muy_e,archV,n_data):\n",
    "    tot_RXY = int(len(rho_AF))\n",
    "    \n",
    "    for j in np.linspace(0,tot_RXY - 1,tot_RXY):\n",
    "        rho,sy,sx = rho_AF[j],sy_AF[j],sx_AF[j]\n",
    "        probxy_evl = bivN_tight(blnkD,x_ne,y_ne,mux_e,muy_e,sx,sy,rho)  # [Ne,Ne,N]\n",
    "        wgt_dat = np.ravel(probxy_evl)\n",
    "        oned_sum_p = np.bincount(oneD_Klist,weights=wgt_dat)  # Sums probabilities explicitly to each N*N_bin^2 knot\n",
    "        pxy_knts = oned_sum_p.reshape((n_data,N_bin,N_bin))  # Recasts in proper [N,y,x] form\n",
    "        archV[rho_IF[j],sy_IF[j],sx_IF[j],:,:,:] = pxy_knts\n",
    "        if (j % int(tot_RXY / 10)) == 0:\n",
    "            print('%i Percent' % (100*j/tot_RXY))\n",
    "    print('Complete')\n",
    "    \n",
    "    return archV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small \"pseudo-index\" routine, preps for lookup table\n",
    "def ryx_indexer(ryx,low,high,step):\n",
    "    return (step - 1)*(ryx - low)/(high - low)\n",
    "\n",
    "\n",
    "# Index limits; also adjusting limits when below, above, or matching indeces\n",
    "def limiter(ind,step):\n",
    "    if ind <= 0:\n",
    "        low_ind,high_ind = 0,1\n",
    "    elif ind >= (step - 1):\n",
    "        low_ind,high_ind = (step - 2),(step - 1)\n",
    "    else:\n",
    "        low_ind,high_ind = np.floor(ind),np.ceil(ind)\n",
    "        if low_ind == high_ind:\n",
    "            low_ind -= 1\n",
    "    return low_ind,high_ind\n",
    "\n",
    "\n",
    "def Pcube_linear(sx,sy,rho,archV):\n",
    "    j_sx = ryx_indexer(sx,btm_sx,top_sx,S_sx)\n",
    "    j_sy = ryx_indexer(sy,btm_sy,top_sy,S_sy)\n",
    "    j_rho = ryx_indexer(rho,btm_rho,top_rho,S_rho)\n",
    "    \n",
    "    wj_sx,hj_sx = limiter(j_sx,S_sx)\n",
    "    wj_sy,hj_sy = limiter(j_sy,S_sy)\n",
    "    wj_rho,hj_rho = limiter(j_rho,S_rho)\n",
    "    \n",
    "    Lx,Ux = j_sx - wj_sx,hj_sx - j_sx\n",
    "    Ly,Uy = j_sy - wj_sy,hj_sy - j_sy\n",
    "    Lro,Uro = j_rho - wj_rho,hj_rho - j_rho\n",
    "    # Normalization (because 'outside' indices blow up L and U)\n",
    "    Troyx = ((np.amax([hj_sx,j_sx,wj_sx]) - np.amin([hj_sx,j_sx,wj_sx]))*\n",
    "             (np.amax([hj_sy,j_sy,wj_sy]) - np.amin([hj_sy,j_sy,wj_sy]))*\n",
    "             (np.amax([hj_rho,j_rho,wj_rho]) - np.amin([hj_rho,j_rho,wj_rho])))\n",
    "    \n",
    "    probxy_knts = (Uro*Uy*Ux*archV[wj_rho,wj_sy,wj_sx,...] +\n",
    "                   Uro*Uy*Lx*archV[wj_rho,wj_sy,hj_sx,...] +\n",
    "                   Uro*Ly*Ux*archV[wj_rho,hj_sy,wj_sx,...] +\n",
    "                   Uro*Ly*Lx*archV[wj_rho,hj_sy,hj_sx,...] +\n",
    "                   Lro*Uy*Ux*archV[hj_rho,wj_sy,wj_sx,...] +\n",
    "                   Lro*Uy*Lx*archV[hj_rho,wj_sy,hj_sx,...] +\n",
    "                   Lro*Ly*Ux*archV[hj_rho,hj_sy,wj_sx,...] +\n",
    "                   Lro*Ly*Lx*archV[hj_rho,hj_sy,hj_sx,...])/Troyx\n",
    "    \n",
    "    return probxy_knts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # # #\n",
    "# INTERLUDE: PBJ Priors & Covariance Pre-Computing\n",
    "# # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SigF_key = True\n",
    "Cov_key = False\n",
    "FastRYX_key = False  # RYX == rho,sigy,sigx == Cov --> keeps key name different-looking\n",
    "\n",
    "P_rP = np.concatenate((pri_AstEcl,pri_DCoeff),axis=1)\n",
    "P_rB = pri_AstEcl\n",
    "P_rJ = np.concatenate((pri_AstEcl,pri_Knots),axis=1)\n",
    "SF_i = 0\n",
    "if Cov_key == True:\n",
    "    P_rP = np.concatenate((P_rP,pri_Cov),axis=1)\n",
    "    P_rB = np.concatenate((P_rB,pri_Cov),axis=1)\n",
    "    P_rJ = np.concatenate((P_rJ,pri_Cov),axis=1)\n",
    "if SigF_key == True:\n",
    "    P_rP = np.concatenate((P_rP,pri_SigF),axis=1)\n",
    "    P_rB = np.concatenate((P_rB,pri_SigF),axis=1)\n",
    "    P_rJ = np.concatenate((P_rJ,pri_SigF),axis=1)\n",
    "    SF_i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PROBABLY don't need because changes above mean priors are regenerating OK.\n",
    "\n",
    "# ndimP,mucorP,ndimB,mucorB,ndimJ,mucorJ,nwalkersJ = np.load(file_Name+'EMCEE_PBJ_dimmucorwalk.npy')\n",
    "# nwalkersP = nwalkersJ\n",
    "# nwalkersB = nwalkersJ\n",
    "\n",
    "# sroirP = np.load(file_Name+'EMCEE_PBJ_priors.npy')\n",
    "# P_rP,P_rB,P_rJ = sroirP[:,:ndimP],sroirP[:,ndimP:ndimP+ndimB],sroirP[:,ndimP+ndimB:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Pre-compute knot probabilities for each data point if fast covariance is turned on\n",
    "if FastRYX_key == True:\n",
    "    DProb_LookTab = covar_preRunner(blank_EvlN,xMesh_nE,yMesh_nE,xNt_E,yNt_E,tempo_DProb,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # # #\n",
    " # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit Pcube_linear(1.43*sigx_cent,2.27*sigy_cent,0.49,DProb_LookTab)\n",
    "\n",
    "# examp_cubeL = np.sum(Pcube_linear(1.43*sigx_cent,2.27*sigy_cent,0.49,DProb_LookTab),axis=0)\n",
    "# examp_CL_img = plt.imshow(examp_cubeL,origin='bottom',interpolation='hermite',cmap=cm.inferno)\n",
    "# plt.colorbar(examp_CL_img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Alternate method for centroid uncertainties on \"P\"-type runs\n",
    "def sigxy_DM_alt(dC_A,xk,yk,sx,sy,rho,archV,n_data):  # dCs = detector Coefficients\n",
    "    d_alone = np.polynomial.polynomial.polyval2d(xk-15.0,yk-15.0,dC_A)\n",
    "    probxy_knts = Pcube_linear(sx,sy,rho,archV)  # [N,N_bin,N_bin]\n",
    "    d_mdl = d_alone*probxy_knts\n",
    "    d_mdl = np.sum(d_mdl,axis=(1,2))\n",
    "    \n",
    "    d_mdl = d_mdl/np.sum(probxy_knts,axis=(1,2))  # Pre flux-weighting: IS IT OK/GOOD???\n",
    "    \n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  Norm to sum = N, so mean d_mdl is near 1.0\n",
    "    return d_mdl  #,np.sum(probxy_knts,axis=(1,2))  # Prob. vals can be noisy, divide by later to quiet((?))\n",
    "\n",
    "# EXAMPLE: sigxy_DM_alt(C_UTin,xKmesh,yKmesh,sigx_cent,sigy_cent,rho_cent,DProb_LookTab,N)\n",
    "# %timeit sigxy_DM_alt(C_UTin,xKmesh,yKmesh,sigx_cent,sigy_cent,rho_cent,DProb_LookTab,N)\n",
    "\n",
    "\n",
    "### Alternate Method for centroid uncertainties on \"B\"-type runs\n",
    "def map_FE_alt(data,ast,sx,sy,rho,archV):\n",
    "    probxy_knts = Pcube_linear(sx,sy,rho,archV)  # [N,N_bin,N_bin]\n",
    "    raw_map = np.sum(probxy_knts,axis=0)  # Converting above into [N_bin,N_bin]\n",
    "    raw_map[raw_map == 0] = 1.0  # Avoiding divide-by-zeros\n",
    "    flux_map = np.sum((data/ast)*np.transpose(probxy_knts,axes=(1,2,0)),axis=2)  # ^^Ditto\n",
    "    dxy_map = flux_map/raw_map  # Of course: flux-weighted, instead of tBK_T dividing!\n",
    "    dxy_map[tmask_goodBKT == False] = 0.0  # Zeroing out bad knots (not BLISS'ed yet)\n",
    "    return dxy_map\n",
    "\n",
    "# EXAMPLE: map_FE_alt(Y_d,A_m,sigx_cent,sigy_cent,rho_cent,DProb_LookTab)\n",
    "# %timeit map_FE_alt(Y_d,A_m,sigx_cent,sigy_cent,rho_cent,DProb_LookTab)\n",
    "\n",
    "\n",
    "### Alternate method for centroid uncertainties on \"J\"-type runs (and maybe \"B\"-type, too)\n",
    "def sigxy_EVM_alt(dxy_sing,theta_K,sx,sy,rho,archV,n_data):\n",
    "    dxy_map = map_flux_jumped(dxy_sing,theta_K)  # [N_bin,N_bin]\n",
    "    probxy_knts = Pcube_linear(sx,sy,rho,archV)  # [N,N_bin,N_bin]\n",
    "    d_mdl = dxy_map*probxy_knts\n",
    "    d_mdl = np.sum(d_mdl,axis=(1,2))  # Collapse to N-length detector model!\n",
    "    \n",
    "    d_mdl = d_mdl/np.sum(probxy_knts,axis=(1,2))  # Pre flux-weighting: is it OK/Good???\n",
    "    \n",
    "#     d_mdl = n_data*d_mdl/np.sum(d_mdl)  #  Norm to sum = N, so mean d_mdl is near 1.0\n",
    "    return d_mdl  #,np.sum(probxy_knts,axis=(1,2)) # Prob. vals can be noisy, divide by later to quiet((?))\n",
    "\n",
    "# Example: sigxy_EVM_alt(Dxy_Solo,Kfl_true,sigx_cent,sigy_cent,rho_cent,DProb_LookTab,N)\n",
    "# %timeit sigxy_EVM_alt(Dxy_Solo,Kfl_true,sigx_cent,sigy_cent,rho_cent,DProb_LookTab,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Test Area for Making Detector Models with Covariance\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scl_fct = 1.0\n",
    "# S_x,S_y,R_xy = scl_fct*sigx_cent,scl_fct*sigy_cent,rho_cent\n",
    "\n",
    "# temp_Ptype = sigxy_detect_model(C_UTin,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,S_x,S_y,R_xy,N)\n",
    "# # temp_PtypeAlt = sigxy_DM_alt(C_UTin,xKmesh,yKmesh,S_x,S_y,R_xy,DProb_LookTab,N)  #,temp_PprobAlt\n",
    "# #\n",
    "# b_ty_flux = map_flux_eval(Y_d,A_m,mask_EtoK,xEmesh_n,yEmesh_n,\n",
    "#                              xNt_vals,yNt_vals,S_x,S_y,R_xy)\n",
    "# temp_Btype = bliss_meth(N,flux_bliss,b_ty_flux,xNt_vals,yNt_vals)\n",
    "# # b_ty_fluxAlt = map_FE_alt(Y_d,A_m,S_x,S_y,R_xy,DProb_LookTab)\n",
    "# # temp_BtypeAlt = bliss_meth(N,flux_bliss,b_ty_fluxAlt,xNt_vals,yNt_vals)\n",
    "# #\n",
    "# temp_Jtype = sigxy_eval_map(Dxy_Solo,Kfl_true,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,\n",
    "#                xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,S_x,S_y,R_xy,N)\n",
    "# # temp_JtypeAlt = sigxy_EVM_alt(Dxy_Solo,Kfl_true,S_x,S_y,R_xy,DProb_LookTab,N)  #,temp_JprobAlt\n",
    "# #\n",
    "# temp_probmap = np.sum(np.transpose(biv_normal(xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,S_x,S_y,R_xy),\n",
    "#                                    axes=(2,0,1))*mask_goodEvl,axis=(1,2))\n",
    "# # temp_probmapAlt = np.sum(np.transpose(bivN_tight(blank_EvlN,xMesh_nE,yMesh_nE,xNt_E,yNt_E,S_x,S_y,R_xy),\n",
    "# #                                    axes=(2,0,1))*mask_goodEvl,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.scatter(Dxy_i,Y/A_m,c='m',alpha=0.5)  # Actual D(xo,yo) WITHOUT the extra \"photon\" noise\n",
    "# plt.scatter(Dxy_i,temp_Ptype,c='g',alpha=0.5)  # \"P\"-types\n",
    "# plt.scatter(Dxy_i,temp_Btype,c='b',alpha=0.5)  # \"B\"-types\n",
    "# plt.scatter(Dxy_i,temp_Jtype,c='r',alpha=0.5)  # \"J\"-types\n",
    "# # plt.scatter(Dxy_i,temp_probmapAlt,c='y',alpha=0.5)  # Total probabilities evaluated for each data point\n",
    "# # plt.scatter(Dxy_i,temp_PtypeAlt/temp_PprobAlt,c=(1,0.75,0),alpha=0.5)  #  Scaling by probability (\"P\"-types)\n",
    "# # plt.scatter(Dxy_i,temp_PtypeAlt - temp_JtypeAlt,c=(1,0.5,0),alpha=0.5)  # Difference in models (\"P\"s - \"J\"s)\n",
    "# # plt.scatter(Dxy_i[:-1],temp_PtypeAlt[:-1] - temp_PtypeAlt[1:],c='0.5',alpha=0.5)  # Time variability (\"P\"-types)\n",
    "# plt.xlabel('$N_{i}$',size=30);\n",
    "# plt.ylabel('$D(x_{o},y_{o})$    |    $\\Sigma P_{i}$',size=30);\n",
    "# plt.title('Testing Detector Models w/ Covariance',size=30)\n",
    "# plt.ylim([0.95,1.05])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Defining Likelihood Functions & Plotting Routines\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accep_B_check = 0  # Diagnostic double-check for acceptance number; dummy initializing here\n",
    "\n",
    "# (Hopefully) Correctly making list of B-Type knots during emcee run!\n",
    "def holdontoknots_Btype(cycle,knot_arch,ss_map,orig):\n",
    "    global accep_B_check\n",
    "    w = int(cycle % nwalkersB)  # walker number\n",
    "    i = int((cycle - w)/nwalkersB)  # emcee step number\n",
    "    if i == 0:\n",
    "        temp_oldKB[w,:] = ss_map[tmask_goodBKT]  # Put 1st knots into 'old' array\n",
    "    elif i == 1:\n",
    "        temp_newKB[w,:] = ss_map[tmask_goodBKT]  # Put 2nd knots into 'new' array\n",
    "    elif i == 2:  # First comparison is unique\n",
    "        if np.all(orig[w,:] == samplerB.chain[w,i-2,:]):  # Check starting point and 1st chain entry for a match\n",
    "            knot_arch[w,i-2,:] = temp_oldKB[w,:]  # Get 'old' if a match (rejected emcee step)\n",
    "        else:\n",
    "            knot_arch[w,i-2,:] = temp_newKB[w,:]  # Get 'new' if NOT a match (accepted emcee step)\n",
    "            temp_oldKB[w,:] = temp_newKB[w,:]  # Move 'new' into 'old'\n",
    "            accep_B_check += 1  # See top\n",
    "        temp_newKB[w,:] = ss_map[tmask_goodBKT]  # Always end by putting current knots into 'new'\n",
    "    else:  # All remaining comparisons\n",
    "        if np.all(samplerB.chain[w,i-3,:] == samplerB.chain[w,i-2,:]):  # Check chain for matches\n",
    "            knot_arch[w,i-2,:] = temp_oldKB[w,:]\n",
    "        else:\n",
    "            knot_arch[w,i-2,:] = temp_newKB[w,:]\n",
    "            temp_oldKB[w,:] = temp_newKB[w,:]\n",
    "            accep_B_check += 1\n",
    "        temp_newKB[w,:] = ss_map[tmask_goodBKT]\n",
    "    return  # Does require a final walker-loop after the chain completes (see emcee B-Type run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cyc_typeB = 0  # Iterator for B-type knot repository; dummy initializing here\n",
    "\n",
    "def data_like(theta,t_sing,y_d,n_data,knot_switch,knot_arch,orig,run_type): # theta has: 3A, 3E, #C, ##K, 3Cov, 1SF\n",
    "    global cyc_typeB\n",
    "    astro = theta[:3]\n",
    "    ecl = theta[3:6]\n",
    "    y_ast = perf_astro_model(l_t,h_t,t_sing,astro,ecl)\n",
    "    if Cov_key == True:\n",
    "        sx,sy,rho = theta[-3+SF_i],theta[-2+SF_i],theta[-1+SF_i]\n",
    "    \n",
    "    if run_type == 'P':\n",
    "        cn_out_Vector[:polyO_out] = theta[6:6+polyO_out]\n",
    "        cn_out_Vector[polyO_out+1:] = theta[6+polyO_out:6+Cn_out]\n",
    "#         dCs = theta[6:6+Cn_out]  # [6:12]\n",
    "        C_UTout[UTout_i] = cn_out_Vector  # dCs\n",
    "        if Cov_key == True:\n",
    "            if FastRYX_key == True:\n",
    "                d_model = sigxy_DM_alt(C_UTout,xKmesh,yKmesh,sx,sy,rho,DProb_LookTab,n_data)  # dCs\n",
    "            else:\n",
    "                d_model = sigxy_detect_model(C_UTout,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,n_data)  # dCs\n",
    "        else:\n",
    "            d_model = perf_detect_model(xNt_vals,yNt_vals,C_UTout,n_data)  # dCs\n",
    "    else:\n",
    "        if run_type == 'B':\n",
    "            if Cov_key == True:\n",
    "                if FastRYX_key == True:\n",
    "                    sens_map = map_FE_alt(y_d,y_ast,sx,sy,rho,DProb_LookTab)\n",
    "                else:\n",
    "                    sens_map = map_flux_eval(y_d,y_ast,mask_EtoK,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho)\n",
    "            else:\n",
    "#                 sens_map = map_flux_avg(y_d,y_ast,Dxy_Full,Dxy_i)\n",
    "                sens_map = map_flux_avgQuick(y_d,y_ast,xNt_B_lin)  # Now runs in [y,x] ordering for consistency\n",
    "            if knot_switch == True:\n",
    "#                 knot_arch[cyc_typeB,:] = sens_map[tmask_goodBKT]\n",
    "                holdontoknots_Btype(cyc_typeB,knot_arch,sens_map,orig)  # Saving B-type knots\n",
    "                cyc_typeB += 1  # Iterator MUST be initialized to 0 BEOFRE starting the MCMC\n",
    "            d_model = bliss_meth(n_data,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "        elif run_type == 'J':\n",
    "            f_knots = theta[6:6+tot_goodK]\n",
    "            if Cov_key == True:\n",
    "                if FastRYX_key == True:\n",
    "                    d_model = sigxy_EVM_alt(Dxy_Solo,f_knots,sx,sy,rho,DProb_LookTab,n_data)\n",
    "                else:\n",
    "                    d_model = sigxy_eval_map(Dxy_Solo,f_knots,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,\n",
    "                                             xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,n_data)\n",
    "            else:\n",
    "                sens_map = map_flux_jumped(Dxy_Solo,f_knots)  # Good JUMP now!\n",
    "                d_model = bliss_meth(n_data,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "    \n",
    "    numer = y_d - (y_ast*d_model)\n",
    "    if SigF_key == True:\n",
    "        sF = theta[-1:]\n",
    "        lglike = -n_data*np.log(sF) - 0.5*np.sum((numer/sF)**2.0)  # Corrected: include \"n_data\"\n",
    "    else:\n",
    "        lglike = -n_data*np.log(SigF_true) - 0.5*np.sum((numer/SigF_true)**2.0)\n",
    "    return lglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit sigxy_detect_model(C_UTin,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent,N)\n",
    "# %timeit perf_detect_model(xNt_vals,yNt_vals,C_UTin,N)\n",
    "# %timeit sigxy_eval_map(Dxy_Solo,Kfl_true,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sigx_cent,sigy_cent,rho_cent,N)\n",
    "# %timeit bliss_meth(N,flux_bliss,map_flux_jumped(Dxy_Solo,Kfl_true),xNt_vals,yNt_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Gauss_key == False:\n",
    "    def data_prior(theta,pri_span):\n",
    "        if np.all(theta < pri_span[0]) and np.all(theta > pri_span[1]):\n",
    "            return 0.0\n",
    "        return -np.inf\n",
    "else:\n",
    "    def data_prior(theta,pri_span):\n",
    "        numer = theta - pri_span[0]\n",
    "        lgpri = -0.5*np.sum((numer/pri_span[1])**2.0)\n",
    "        return lgpri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig_below_Zero(theta):\n",
    "    sF_num = 0\n",
    "    if SigF_key == True:\n",
    "        if theta[-1] <= 0:\n",
    "            return True\n",
    "        sF_num = -1\n",
    "    if Cov_key == True:\n",
    "        if np.any(theta[(-3+sF_num):(-1+sF_num)] <= 0) or (np.absolute(theta[-1+sF_num]) > 1.0):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bogus_ssmap = np.zeros((N_bin,N_bin))  # Placeholder for below, when you KNOW the emcee step CANNOT be accepted\n",
    "\n",
    "def data_post(theta,t_sing,y_d,n_data,knot_switch,knot_arch,orig,pri_span,run_type):\n",
    "    global cyc_typeB\n",
    "    if sig_below_Zero(theta) == True:\n",
    "        if run_type == 'B':  # Assume non-Cov. runs for now\n",
    "            if knot_switch == True:\n",
    "#                 knot_arch[cyc_typeB,:] = knot_arch[cyc_typeB-nwalkersB,:]\n",
    "                holdontoknots_Btype(cyc_typeB,knot_arch,bogus_ssmap,orig)  # Saving B-type knots\n",
    "                cyc_typeB += 1\n",
    "        return -np.inf\n",
    "    lgpri = data_prior(theta,pri_span)\n",
    "    if not np.isfinite(lgpri):\n",
    "        if run_type == 'B':\n",
    "            if knot_switch == True:\n",
    "#                 knot_arch[cyc_typeB,:] = knot_arch[cyc_typeB-nwalkersB,:]\n",
    "                holdontoknots_Btype(cyc_typeB,knot_arch,bogus_ssmap,orig)  # Saving B-type knots\n",
    "                cyc_typeB += 1\n",
    "        return -np.inf\n",
    "    return lgpri + data_like(theta,t_sing,y_d,n_data,knot_switch,knot_arch,orig,run_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit data_post(p0B,T,Y_d,N,P_rB,'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_labels = np.array([r'$\\alpha_{A}$','$f_{A}$','$\\phi_{A}$',\n",
    "                     '$t_{e}$','$\\hbar\\omega_{e}$','$\\delta_{e}$',\n",
    "                     r'$\\sigma_{x_{0}}$',r'$\\sigma_{y_{0}}$',r'$\\rho_{xy}$','$\\sigma_{F}$'],dtype='object_')\n",
    "# Pc_labels = np.array(['$c_{x^{2}}$','$c_{xy}$','$c_{y^{2}}$','$c_{x}$','$c_{y}$','$c_{0}$'],dtype='object_')\n",
    "Pc_labels = np.empty(Cn_out,dtype='object_')\n",
    "DCs_fit_true,DCs_fit_plotty = np.zeros(Cn_out),np.zeros(Cn_out)  # Version 'plotty' for plots later\n",
    "pcl_i = 0\n",
    "pcl_bump = 0  # To increase lookup index after c_00 term\n",
    "inout_diff = polyO_in - polyO_out\n",
    "for x in np.linspace(polyO_out,0,polyO_out+1):  # In or out poly can be larger since indexes work either way!\n",
    "    for y in np.linspace(x,0,x+1):\n",
    "        if (y == 0) and (polyO_out-x == 0):  # Avoid c_00 term\n",
    "            pcl_bump = 1\n",
    "        else:\n",
    "            Pc_labels[pcl_i] = '$c_{y=%i}^{x=%i}$' % (y,polyO_out-x)\n",
    "            if ((y + (polyO_out - x)) > polyO_in):\n",
    "                DCs_fit_true[pcl_i] = 1e-4  # Not 0.0 to avoid stacking walkers on top of each other\n",
    "                DCs_fit_plotty[pcl_i] = 0.0\n",
    "            else:\n",
    "                DCs_fit_true[pcl_i] = DCs_true[pcl_i + pcl_bump + inout_diff*(polyO_out + 1 - x)]\n",
    "                DCs_fit_plotty[pcl_i] = DCs_true[pcl_i + pcl_bump + inout_diff*(polyO_out + 1 - x)]\n",
    "            pcl_i += 1\n",
    "pcl_i,pcl_bump = 0,0\n",
    "\n",
    "# DCs_fit_true = np.load(file_Name+'EMCEE_PBJ_true.npy')[6+(Cn_in+1):6+(Cn_in+1)+Cn_out]\n",
    "\n",
    "def AstEcl_corner(samp,burn,inc):\n",
    "    thin_dat = samp.chain[:,burn::inc,:]  # Better chain thinning \n",
    "    n_it = thin_dat.shape\n",
    "    flatdata = thin_dat.reshape((n_it[0]*n_it[1],n_it[2]))\n",
    "    \n",
    "    if (Cov_key == True) and (SigF_key == True):\n",
    "        walk_data = np.concatenate((flatdata[:,:6],flatdata[:,-4:]),axis=1)  # Before: [::inc,etc.]\n",
    "        fig = corner.corner(walk_data,labels=v_labels,label_kwargs={'fontsize':30},\n",
    "                            truths=np.concatenate((Ast_true,Ecl_true,Cov_true,SigF_true)))\n",
    "    elif (Cov_key == True) and (SigF_key == False):\n",
    "        walk_data = np.concatenate((flatdata[:,:6],flatdata[:,-3:]),axis=1)\n",
    "        fig = corner.corner(walk_data,labels=np.concatenate((v_labels[:6],v_labels[-3:])),\n",
    "                            label_kwargs={'fontsize':30},truths=np.concatenate((Ast_true,Ecl_true,Cov_true)))\n",
    "    elif (Cov_key == False) and (SigF_key == True):\n",
    "        walk_data = np.concatenate((flatdata[:,:6],flatdata[:,-1:]),axis=1)\n",
    "        fig = corner.corner(walk_data,labels=np.concatenate((v_labels[:6],v_labels[-1:])),\n",
    "                            label_kwargs={'fontsize':30},truths=np.concatenate((Ast_true,Ecl_true,SigF_true)))\n",
    "    else:\n",
    "        fig = corner.corner(flatdata[:,:6],labels=v_labels[:6],label_kwargs={'fontsize':30},\n",
    "                            truths=np.concatenate((Ast_true,Ecl_true)))\n",
    "    return\n",
    "\n",
    "def Coeff_corner(samp,burn,inc):\n",
    "    thin_dat = samp.chain[:,burn::inc,:]  # Better chain thinning\n",
    "    n_it = thin_dat.shape\n",
    "    flatdata = thin_dat.reshape((n_it[0]*n_it[1],n_it[2]))\n",
    "    \n",
    "    fig = corner.corner(flatdata[:,6:6+polyO_out],labels=Pc_labels[0:polyO_out],\n",
    "                        label_kwargs={'fontsize':30},truths=DCs_fit_plotty[0:polyO_out])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indiv_plots(n):\n",
    "    plt.figure(n,figsize=(12,6))\n",
    "    plt.xlim([l_t,h_t]);\n",
    "    plt.xlabel('$t$',size=30);\n",
    "    \n",
    "def AFD_style(samp,burn,draws,run_type,inc):\n",
    "    indiv_plots(1)\n",
    "    plt.scatter(T,Y_d/D_m,c='k',alpha=0.1,zorder=1)\n",
    "    plt.ylabel('$A(t)$',size=30);\n",
    "    plt.plot(T,A_m,'g',linewidth=2,zorder=3)\n",
    "    plt.ylim([Am_dw - 0.2*Am_scl,Am_up + 0.2*Am_scl])\n",
    "    \n",
    "    indiv_plots(2)\n",
    "    plt.scatter(T,Y_d,c='k',alpha=0.1,zorder=1)\n",
    "    plt.ylabel('$F(t)$',size=30);\n",
    "    plt.plot(T,Y,'r',linewidth=2,zorder=3)\n",
    "    plt.ylim([Yd_dw - 0.1*Yd_scl,Yd_up + 0.1*Yd_scl])\n",
    "    \n",
    "    indiv_plots(3)\n",
    "    plt.scatter(T,Y_d/A_m,c='k',alpha=0.1,zorder=1)\n",
    "    plt.ylabel('$D(x_{0},y_{0})$',size=30);\n",
    "    plt.plot(T,D_m,'m',linewidth=2,zorder=3)\n",
    "    plt.ylim([Dm_dw - 0.2*Dm_scl,Dm_up + 0.2*Dm_scl])\n",
    "    \n",
    "    thin_dat = samp.chain[:,burn::inc,:]  # Better chain thinning\n",
    "    n_it = thin_dat.shape\n",
    "    flatdata = thin_dat.reshape((n_it[0]*n_it[1],n_it[2]))\n",
    "   \n",
    "    for theta in flatdata[np.random.randint(len(flatdata),size=draws)]:  # Before: [::inc,:]\n",
    "        astro = theta[:3]\n",
    "        ecl = theta[3:6]\n",
    "        y_ast = perf_astro_model(l_t,h_t,T,astro,ecl)\n",
    "        if Cov_key == True:\n",
    "            sx,sy,rho = theta[-3+SF_i],theta[-2+SF_i],theta[-1+SF_i]\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.plot(T,y_ast,'k',alpha=0.1,zorder=2)\n",
    "        \n",
    "        if run_type == 'P':\n",
    "            cn_out_Vector[:polyO_out] = theta[6:6+polyO_out]\n",
    "            cn_out_Vector[polyO_out+1:] = theta[6+polyO_out:6+Cn_out]\n",
    "#             dCs = theta[6:6+Cn_out]  # [6:12]\n",
    "            C_UTout[UTout_i] = cn_out_Vector  # dCs\n",
    "            if Cov_key == True:\n",
    "                if FastRYX_key == True:\n",
    "                    d_model = sigxy_DM_alt(C_UTout,xKmesh,yKmesh,sx,sy,rho,DProb_LookTab,N)  # dCs\n",
    "                else:\n",
    "                    d_model = sigxy_detect_model(C_UTout,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,N)  # dCs\n",
    "            else:\n",
    "                d_model = perf_detect_model(xNt_vals,yNt_vals,C_UTout,N)  # dCs\n",
    "            plt.figure(1)\n",
    "            plt.title('Astro POLY',size=30)\n",
    "            plt.figure(2)\n",
    "            plt.title('Full POLY',size=30)\n",
    "            plt.figure(3)\n",
    "            plt.title('Detector POLY',size=30)\n",
    "        else:\n",
    "            if run_type == 'B':\n",
    "                if Cov_key == True:\n",
    "                    if FastRYX_key == True:\n",
    "                        sens_map = map_FE_alt(Y_d,y_ast,sx,sy,rho,DProb_LookTab)\n",
    "                    else:\n",
    "                        sens_map = map_flux_eval(Y_d,y_ast,mask_EtoK,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho)\n",
    "                    d_model = bliss_meth(N,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "                else:\n",
    "#                     sens_map = map_flux_avg(Y_d,y_ast,Dxy_Full,Dxy_i)\n",
    "                    sens_map = map_flux_avgQuick(Y_d,y_ast,xNt_B_lin)\n",
    "                    d_model = bliss_meth(N,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "                plt.figure(1)\n",
    "                plt.title('Astro BLISS',size=30)\n",
    "                plt.figure(2)\n",
    "                plt.title('Full BLISS',size=30)\n",
    "                plt.figure(3)\n",
    "                plt.title('Detector BLISS',size=30)\n",
    "            elif run_type == 'J':\n",
    "                f_knots = theta[6:6+tot_goodK]\n",
    "                if Cov_key == True:\n",
    "                    if FastRYX_key == True:\n",
    "                        d_model = sigxy_EVM_alt(Dxy_Solo,f_knots,sx,sy,rho,DProb_LookTab,N)\n",
    "                    else:\n",
    "                        d_model = sigxy_eval_map(Dxy_Solo,f_knots,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,\n",
    "                                                 xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,N)\n",
    "                else:\n",
    "                    sens_map = map_flux_jumped(Dxy_Solo,f_knots)\n",
    "                    d_model = bliss_meth(N,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "                plt.figure(1)\n",
    "                plt.title('Astro JUMP',size=30)\n",
    "                plt.figure(2)\n",
    "                plt.title('Full JUMP',size=30)\n",
    "                plt.figure(3)\n",
    "                plt.title('Detector JUMP',size=30)\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.plot(T,y_ast*d_model,'k',alpha=0.1,zorder=2)\n",
    "        plt.figure(3)\n",
    "        plt.plot(T,d_model,'k',alpha=0.1,zorder=2)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def walk_style(ndim,nwalk,samp,burn,inc,run_type):  # inc is take every # element (thins out plots)\n",
    "    max_t = samp.chain.shape[1]\n",
    "    t_V = np.linspace(1,max_t,max_t)\n",
    "    t_V = t_V[burn::inc]\n",
    "    j_easy = 25  # To thin the number of knots plotted\n",
    "    \n",
    "    unc_C = 0\n",
    "    unc_F = 0\n",
    "    if Cov_key == True:\n",
    "        unc_C = 3\n",
    "    if SigF_key == True:\n",
    "        unc_F = 1\n",
    "    \n",
    "    if run_type == 'P':\n",
    "        nrows = np.ceil(ndim/4)\n",
    "        plt.figure(figsize=(16,3*nrows))\n",
    "    elif run_type == 'B':\n",
    "        plt.figure(figsize=(16,9))\n",
    "    elif run_type == 'J':\n",
    "        nrows = np.ceil((ndim + j_easy*10)/(4*j_easy))\n",
    "        plt.figure(figsize=(16,3*nrows))\n",
    "        \n",
    "    jin = 7  # Special knot indexing\n",
    "    for j in np.linspace(0,ndim-1,ndim):\n",
    "        if run_type == 'P':\n",
    "            plt.subplot(nrows,4,j+1)\n",
    "        elif run_type == 'B':\n",
    "            plt.subplot(3,4,j+1)\n",
    "        elif run_type == 'J':\n",
    "            if (j >= 6) and (j < (ndim - unc_C - unc_F)):\n",
    "                if ((j-6) % j_easy) == 0:\n",
    "                    plt.subplot(nrows,4,jin)\n",
    "                    jin += 1\n",
    "                else:\n",
    "                    continue\n",
    "            elif j >= (ndim - unc_C - unc_F):\n",
    "                plt.subplot(nrows,4,jin)\n",
    "                jin += 1\n",
    "            else:\n",
    "                plt.subplot(nrows,4,j+1)\n",
    "        mu_param = np.mean(samp.chain[:,:,j][:,burn::inc],axis=0)\n",
    "        std_param = np.std(samp.chain[:,:,j][:,burn::inc],axis=0)\n",
    "        plt.plot(t_V,mu_param,'k--')\n",
    "        plt.fill_between(t_V,mu_param + 3.0*std_param,mu_param - 3.0*std_param,facecolor='k',alpha=0.1)\n",
    "        plt.fill_between(t_V,mu_param + 2.0*std_param,mu_param - 2.0*std_param,facecolor='k',alpha=0.1)\n",
    "        plt.fill_between(t_V,mu_param + 1.0*std_param,mu_param - 1.0*std_param,facecolor='k',alpha=0.1)\n",
    "        \n",
    "        if j < 3:\n",
    "            plt.title(v_labels[j],size=16)\n",
    "            plt.plot(np.array([0,max_t]),np.array([Ast_true[j],Ast_true[j]]),'g',linewidth=2)\n",
    "        elif j < 6:\n",
    "            plt.title(v_labels[j],size=16)\n",
    "            plt.plot(np.array([0,max_t]),np.array([Ecl_true[j-3],Ecl_true[j-3]]),'y',linewidth=2)\n",
    "        elif (run_type == 'P') and (j < (6 + Cn_out)):  # (j < 12)\n",
    "            plt.title(Pc_labels[j-6],size=16)  #\n",
    "            plt.plot(np.array([0,max_t]),np.array([DCs_fit_plotty[j-6],DCs_fit_plotty[j-6]]),'m',linewidth=2)\n",
    "        elif (run_type == 'J') and (j < (ndim - unc_C - unc_F)):\n",
    "            if ((j-6) % j_easy) == 0:  # Going easy on the J plotting :-)\n",
    "                plt.title('Knot %i' % int(j-6))\n",
    "                plt.plot(np.array([0,max_t]),np.array([Kfl_true[j-6],Kfl_true[j-6]]),'m',linewidth=2)\n",
    "        elif (Cov_key == True) and (j < (ndim - unc_F)):\n",
    "            plt.title(v_labels[j - (ndim - unc_F) + 9],size=16)  # '+9' will change [-3,-1] into [6,8]!\n",
    "            plt.plot(np.array([0,max_t]),np.array([Cov_true[j-(ndim-unc_F)+3],Cov_true[j-(ndim-unc_F)+3]]),\n",
    "                     color=(1,0.5,0),linewidth=2)  # '+3' will change [-3,-1] into [0,2]!\n",
    "        elif (SigF_key == True):\n",
    "            plt.title(v_labels[9],size=16)\n",
    "            plt.plot(np.array([0,max_t]),np.array([SigF_true,SigF_true]),color=(1,0.5,0),linewidth=2)\n",
    "        if j < (ndim-4):\n",
    "            plt.xticks([])\n",
    "        else:\n",
    "            plt.xticks(rotation=25)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# RUNNING DIFFERENT TYPES OF MCMC BELOW HERE\n",
    "# \"P\": POLY-LIKE, WITH ASTRO, ECLIPSE, AND POLY-DETECT PARAMS (NO BLISS)\n",
    "# \"B\": BLISS-LIKE, WITH ONLY ASTRO AND ECLIPSE PARAMS\n",
    "# \"J\": JUMP-LIKE, INCLUDING ALL KNOTS AS FREE PARAMS\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndimP,ndimB,ndimJ,nwalkersJ = 6+Cn_out,6,6+tot_goodK,3*(6+tot_goodK+((6+tot_goodK) % 2))  # P = 12 before\n",
    "if SigF_key == True:\n",
    "    ndimP += 1\n",
    "    ndimB += 1\n",
    "    ndimJ += 1\n",
    "    nwalkersJ += 4\n",
    "    r_SigF = np.random.randn(1)\n",
    "if Cov_key == True:\n",
    "    ndimP += 3\n",
    "    ndimB += 3\n",
    "    ndimJ += 3\n",
    "    nwalkersJ += 12\n",
    "    r_Cov = np.random.randn(3)\n",
    "nwalkersP = nwalkersJ\n",
    "nwalkersB = nwalkersJ  # Keeping things consistent\n",
    "\n",
    "# ndimP,mucorP,ndimB,mucorB,ndimJ,mucorJ,nwalkersJ = np.load(file_Name+'EMCEE_PBJ_dimmucorwalk.npy')\n",
    "# nwalkersP = nwalkersJ\n",
    "# nwalkersB = nwalkersJ\n",
    "\n",
    "r_AstEcl,r_DCoeff,r_Knots = np.random.randn(6),np.random.randn(Cn_out),np.random.randn(tot_goodK)\n",
    "\n",
    "rdev_P = np.concatenate((r_AstEcl,r_DCoeff))\n",
    "rdev_B = r_AstEcl\n",
    "rdev_J = np.concatenate((r_AstEcl,r_Knots))\n",
    "\n",
    "o_AstEcl = np.random.randn(nwalkersJ*6).reshape(nwalkersJ,6)\n",
    "o_DCoeff = np.random.randn(nwalkersJ*Cn_out).reshape(nwalkersJ,Cn_out)\n",
    "o_Knots = np.random.randn(nwalkersJ*tot_goodK).reshape(nwalkersJ,tot_goodK)\n",
    "\n",
    "off_P = np.concatenate((o_AstEcl,o_DCoeff),axis=1)\n",
    "off_B = o_AstEcl\n",
    "off_J = np.concatenate((o_AstEcl,o_Knots),axis=1)\n",
    "\n",
    "real_P = np.concatenate((Ast_true,Ecl_true,DCs_fit_true))\n",
    "real_B = np.concatenate((Ast_true,Ecl_true))\n",
    "real_J = np.concatenate((Ast_true,Ecl_true,Kfl_true))\n",
    "\n",
    "if Cov_key == True:\n",
    "    o_Cov = np.random.randn(nwalkersJ*3).reshape(nwalkersJ,3)\n",
    "    rdev_P = np.concatenate((rdev_P,r_Cov))\n",
    "    rdev_B = np.concatenate((rdev_B,r_Cov))\n",
    "    rdev_J = np.concatenate((rdev_J,r_Cov))\n",
    "    off_P = np.concatenate((off_P,o_Cov),axis=1)\n",
    "    off_B = np.concatenate((off_B,o_Cov),axis=1)\n",
    "    off_J = np.concatenate((off_J,o_Cov),axis=1)\n",
    "    real_P = np.concatenate((real_P,Cov_true))\n",
    "    real_B = np.concatenate((real_B,Cov_true))\n",
    "    real_J = np.concatenate((real_J,Cov_true))\n",
    "if SigF_key == True:\n",
    "    o_SigF = np.random.randn(nwalkersJ).reshape(nwalkersJ,1)\n",
    "    rdev_P = np.concatenate((rdev_P,r_SigF))\n",
    "    rdev_B = np.concatenate((rdev_B,r_SigF))\n",
    "    rdev_J = np.concatenate((rdev_J,r_SigF))\n",
    "    off_P = np.concatenate((off_P,o_SigF),axis=1)\n",
    "    off_B = np.concatenate((off_B,o_SigF),axis=1)\n",
    "    off_J = np.concatenate((off_J,o_SigF),axis=1)\n",
    "    real_P = np.concatenate((real_P,SigF_true))\n",
    "    real_B = np.concatenate((real_B,SigF_true))\n",
    "    real_J = np.concatenate((real_J,SigF_true)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NOW you can apply all the above.....obnoxious!\n",
    "r_scaling = 1e-3  # 1e-4\n",
    "o_scaling = 1e-4  # 1e-4\n",
    "\n",
    "p0P = real_P*(1.0 + r_scaling*rdev_P)\n",
    "p0B = real_B*(1.0 + r_scaling*rdev_B)\n",
    "p0J = real_J*(1.0 + r_scaling*rdev_J)\n",
    "\n",
    "pZP = p0P*(1.0 + o_scaling*off_P)\n",
    "pZB = p0B*(1.0 + o_scaling*off_B)\n",
    "pZJ = p0J*(1.0 + o_scaling*off_J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mini_thinner(mychain,burn,inc):\n",
    "    thin_dat = mychain[:,burn::inc,:]  # Better chain thinning\n",
    "    n_it = thin_dat.shape\n",
    "    flatdata = thin_dat.reshape((n_it[0]*n_it[1],n_it[2]))\n",
    "    return flatdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #\n",
    "\n",
    "Dump_key = False\n",
    "Viz_key = True\n",
    "Clear_key = False\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bonus_name = ''  # If you need an extra qualifier\n",
    "# file_Name_svr = 'Data_Info/'+bonus_name+my_mini_fcall  # Description of dataset\n",
    "\n",
    "# if Dump_key == True:\n",
    "#     if yesdoP == True:\n",
    "#         np.save(file_Name_svr+'bliss_P_thinflat',mini_thinner(samplerP.chain,0,int(mucorP)))\n",
    "#         np.save(file_Name_svr+'bliss_P_chain',samplerP.chain)\n",
    "#         np.save(file_Name_svr+'bliss_P_prob',samplerP.lnprobability)\n",
    "#     else:\n",
    "#         gP_chisq,gP_bic = 0,0\n",
    "#         ptls_P = np.ones((3,ndimP))\n",
    "#         posP = np.ones((nwalkersP,ndimP))\n",
    "        \n",
    "#     np.save(file_Name_svr+'bliss_B_thinflat',mini_thinner(samplerB.chain,0,int(mucorB)))\n",
    "#     np.save(file_Name_svr+'bliss_B_chain',samplerB.chain)\n",
    "#     np.save(file_Name_svr+'bliss_B_thinflatKrepo',mini_thinner(K_repo_typeB,0,int(mucorB)))\n",
    "#     np.save(file_Name_svr+'bliss_B_Krepo',K_repo_typeB)\n",
    "#     np.save(file_Name_svr+'bliss_B_prob',samplerB.lnprobability)\n",
    "    \n",
    "#     if yesdoJ == True:\n",
    "#         np.save(file_Name_svr+'bliss_J_thinflat',mini_thinner(samplerJ.chain,0,int(mucorJ)))\n",
    "#         np.save(file_Name_svr+'bliss_J_chain',samplerJ.chain)\n",
    "#         np.save(file_Name_svr+'bliss_J_prob',samplerJ.lnprobability)\n",
    "#     else:\n",
    "#         gJ_chisq,gJ_bic = 0,0\n",
    "#         ptls_J = np.ones((3,ndimJ))\n",
    "#         posJ = np.ones((nwalkersJ,ndimJ))\n",
    "    \n",
    "#     np.save(file_Name_svr+'EMCEE_PBJ_percentiles',np.concatenate((ptls_P,ptls_B,ptls_J),axis=1))\n",
    "#     np.save(file_Name_svr+'PBJ_onlyEcl_ptls',np.concatenate((ptls_P[:,5],ptls_B[:,5],ptls_J[:,5])))\n",
    "#     np.save(file_Name_svr+'EMCEE_PBJ_positions',np.concatenate((posP,posB,posJ),axis=1))\n",
    "#     np.save(file_Name_svr+'EMCEE_PBJ_priors',np.concatenate((P_rP,P_rB,P_rJ),axis=1))\n",
    "    \n",
    "#     np.save(file_Name_svr+'EMCEE_PBJ_dimmucorwalk',np.array([ndimP,mucorP,ndimB,mucorB,ndimJ,mucorJ,nwalkersJ]))\n",
    "#     np.save(file_Name_svr+'EMCEE_PBJ_chiBIC',np.array([gP_chisq,gP_bic,gB_chisq,gB_bic,gB_chisq+ndimB*np.log(N),\n",
    "#                                                    gJ_chisq,gJ_bic]))\n",
    "#     np.save(file_Name_svr+'PBJ_Betas',np.array([ppp_Beta,bbb_Beta,jjj_Beta]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Bringing back last positions of chains\n",
    "\n",
    "# snoiT = np.load(file_Name+'EMCEE_PBJ_positions.npy')\n",
    "# posP,posB,posJ = snoiT[:,:ndimP],snoiT[:,ndimP:ndimP+ndimB],snoiT[:,ndimP+ndimB:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Timing Values\n",
    "search_S = 1e2  # 2.5e3\n",
    "pare_S = search_S/50  # /50\n",
    "\n",
    "TwoPlus_key = False  # Meaning: Are you continuing a chain you just ran?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### P-Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplerP = emcee.EnsembleSampler(nwalkersP,ndimP,data_post,args=[T,Y_d,N,False,'N/A',pZP,P_rP,'P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if yesdoP == True:\n",
    "    if TwoPlus_key == False:\n",
    "        posP,probP,stateP = samplerP.run_mcmc(pZP,int(search_S));\n",
    "    elif TwoPlus_key == True:\n",
    "        posP,probP,stateP = samplerP.run_mcmc(posP,int(search_S));  # Run more from end of last chain\n",
    "\n",
    "    print('Mean Acceptance Fraction: {0:.5f}'.format(np.mean(samplerP.acceptance_fraction)))\n",
    "    mucorP = np.amax(samplerP.get_autocorr_time())\n",
    "    print('Highest Autocorrelation Time: %.2f' % mucorP)\n",
    "    # flatD_P = samplerP.flatchain\n",
    "else:\n",
    "    mucorP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    walk_style(ndimP,nwalkersP,samplerP,0,int(pare_S),'P')  # burn_Sp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P Stats Starting Iteration\n",
    "burn_Sp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(samplerP.lnprobability[:,burn_Sp:].flat,200,normed=True,color='g');\n",
    "    plt.xlabel('$logP$',size=30);\n",
    "    plt.ylabel('PDF',size=30);\n",
    "    plt.title('Posteriors POLY',size=30);\n",
    "    plt.show()\n",
    "\n",
    "    lnhP = np.amax(samplerP.lnprobability[:,burn_Sp:].flat)\n",
    "else:\n",
    "    lnhP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    AstEcl_corner(samplerP,burn_Sp,int(mucorP))  # flatD_P\n",
    "    Coeff_corner(samplerP,burn_Sp,int(mucorP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    AFD_style(samplerP,burn_Sp,50,'P',int(mucorP))  # flatD_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if Clear_key == True:\n",
    "# #     del flatD_P;\n",
    "#     samplerP.reset();\n",
    "#     gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### B-Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparing BLISS Knot Repository\n",
    "K_repo_typeB = np.zeros((nwalkersB,search_S,tot_goodK))\n",
    "temp_oldKB,temp_newKB = np.zeros((nwalkersB,tot_goodK)),np.zeros((nwalkersB,tot_goodK))\n",
    "cyc_typeB = 0  # Important: initializing iterator for knot archive\n",
    "accep_B_check = 0  # Diagnostic iterator\n",
    "\n",
    "# K_repo_typeB = np.zeros((nwalkersB*(search_S+1),tot_goodK))  # Because emcee runs an extra step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if TwoPlus_key == False:\n",
    "    samplerB = emcee.EnsembleSampler(nwalkersB,ndimB,data_post,args=[T,Y_d,N,True,K_repo_typeB,pZB,P_rB,'B'])\n",
    "elif TwoPlus_key == True:\n",
    "    samplerB = emcee.EnsembleSampler(nwalkersB,ndimB,data_post,args=[T,Y_d,N,True,K_repo_typeB,posB,P_rB,'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if TwoPlus_key == False:\n",
    "    posB,probB,stateB = samplerB.run_mcmc(pZB,int(search_S));\n",
    "elif TwoPlus_key == True:\n",
    "    posB,probB,stateB = samplerB.run_mcmc(posB,int(search_S));  # Run more from end of last chain\n",
    "\n",
    "print('Mean Acceptance Fraction: {0:.5f}'.format(np.mean(samplerB.acceptance_fraction)))\n",
    "mucorB = np.amax(samplerB.get_autocorr_time())\n",
    "print('Highest Autocorrelation Time: %.2f' % mucorB)\n",
    "# flatD_B = samplerB.flatchain\n",
    "# print(cyc_typeB)\n",
    "cyc_typeB = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final walker-loop to fill out knot repository\n",
    "for w in np.linspace(0,nwalkersB-1,nwalkersB):\n",
    "    if np.all(samplerB.chain[w,int(search_S-2),:] == samplerB.chain[w,int(search_S-1),:]):  # Match check\n",
    "        K_repo_typeB[w,int(search_S-1),:] = temp_oldKB[w,:]  # Get 'old' if a match (rejected emcee step)\n",
    "    else:\n",
    "        K_repo_typeB[w,int(search_S-1),:] = temp_newKB[w,:]  # Get 'new' if NOT a match (accepted emcee step)\n",
    "        accep_B_check += 1  # Tally accepted step\n",
    "\n",
    "print('Good-jump fraction (compare above): %.5f' % (accep_B_check/(nwalkersB*search_S)))\n",
    "accep_B_check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if Viz_key == True:\n",
    "    walk_style(ndimB,nwalkersB,samplerB,0,int(pare_S),'B')  # burn_Sb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B Stats Starting Iteration\n",
    "burn_Sb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(samplerB.lnprobability[:,burn_Sb:].flat,200,normed=True,color='b');\n",
    "plt.xlabel('$logP$',size=30);\n",
    "plt.ylabel('PDF',size=30);\n",
    "plt.title('Posteriors BLISS',size=30);\n",
    "plt.show()\n",
    "\n",
    "lnhB = np.amax(samplerB.lnprobability[:,burn_Sb:].flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if Viz_key == True:\n",
    "    AstEcl_corner(samplerB,burn_Sb,int(mucorB))  # flatD_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if Viz_key == True:\n",
    "    AFD_style(samplerB,burn_Sb,50,'B',int(mucorB))  # flatD_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comparing B-type and 'Actual' Knots\n",
    "# Kmu_typeB = np.mean(K_repo_typeB[:,burn_Sb::int(mucorB),:],axis=(0,1))\n",
    "# Kstd_typeB = np.std(K_repo_typeB[:,burn_Sb::int(mucorB),:],axis=(0,1))\n",
    "Kmu_typeB = np.mean(mini_thinner(K_repo_typeB,0,int(mucorB)),axis=0)\n",
    "Kstd_typeB = np.std(mini_thinner(K_repo_typeB,0,int(mucorB)),axis=0)\n",
    "\n",
    "# Kmu_typeB = np.mean(Kchained_typeB[:,burn_Sb::int(mucorB),:],axis=(0,1))\n",
    "# Kstd_typeB = np.std(Kchained_typeB[:,burn_Sb::int(mucorB),:],axis=(0,1))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for i in np.linspace(0,tot_goodK-1,tot_goodK):\n",
    "    plt.scatter(i,Kfl_true[i],marker='x',s=75,c='m',zorder=2)\n",
    "    plt.scatter(i,Kmu_typeB[i],s=50,c='b',zorder=2)\n",
    "    if i == 0:\n",
    "        plt.legend(('Actual','BLISS'),bbox_to_anchor=(1.15,0.8))\n",
    "    plt.plot(np.array([i,i]),np.array([Kmu_typeB[i] - Kstd_typeB[i],Kmu_typeB[i] + Kstd_typeB[i]]),\n",
    "             lw=3,c='0.75',zorder=1)\n",
    "plt.xlim([-1,tot_goodK]);\n",
    "plt.xlabel('$K_{i}$',size=30);\n",
    "plt.ylabel(r'$\\bar F$',size=30);\n",
    "plt.title('Knots: B-Type vs Actual',size=30);\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for i in np.linspace(0,tot_goodK-1,tot_goodK):\n",
    "    plt.scatter(i,Kmu_typeB[i] - Kfl_true[i],s=50,c='b',zorder=2)\n",
    "    if i == 0:\n",
    "        plt.plot(i,0,lw=3,ls='--',c='m',zorder=2)\n",
    "        plt.legend(('Actual','BLISS'),bbox_to_anchor=(1.15,0.8))\n",
    "    plt.plot(np.array([i,i]),np.array([Kmu_typeB[i] - Kstd_typeB[i] - Kfl_true[i],\n",
    "                                       Kmu_typeB[i] + Kstd_typeB[i] - Kfl_true[i]]),\n",
    "             lw=3,c='0.75',zorder=1)\n",
    "plt.plot(np.array([-1,tot_goodK]),np.array([0,0]),lw=3,c='m',ls='--',zorder=1)\n",
    "plt.fill_between(np.array([-1,tot_goodK]),np.std(Kfl_true),-np.std(Kfl_true),\n",
    "                color='m',alpha='0.1')\n",
    "plt.xlim([-1,tot_goodK]);\n",
    "plt.xlabel('$K_{i}$',size=30);\n",
    "plt.ylabel(r'$\\Delta\\bar F$',size=30);\n",
    "plt.title('Knots: B-Type - Actual',size=30);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if Clear_key == True:\n",
    "# #     del flatD_B;\n",
    "#     samplerB.reset();\n",
    "#     gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### J-Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samplerJ = emcee.EnsembleSampler(nwalkersJ,ndimJ,data_post,args=[T,Y_d,N,False,'N/A',pZJ,P_rJ,'J'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    if TwoPlus_key == False:\n",
    "        posJ,probJ,stateJ = samplerJ.run_mcmc(pZJ,int(2*search_S));  # Since takes longer\n",
    "    elif TwoPlus_key == True:\n",
    "        posJ,probJ,stateJ = samplerJ.run_mcmc(posJ,int(search_S));  # Run more from end of last chain\n",
    "\n",
    "    print('Mean Acceptance Fraction: {0:.5f}'.format(np.mean(samplerJ.acceptance_fraction)))\n",
    "    mucorJ = np.amax(samplerJ.get_autocorr_time())\n",
    "    print('Highest Autocorrelation Time: %.2f' % mucorJ)\n",
    "    # flatD_J = samplerJ.flatchain\n",
    "else:\n",
    "    mucorJ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    walk_style(ndimJ,nwalkersJ,samplerJ,0,int(pare_S),'J')  # burn_Sj?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# J Stats Starting Iteration\n",
    "burn_Sj = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(samplerJ.lnprobability[:,burn_Sj:].flat,200,normed=True,color='r');\n",
    "    plt.xlabel('$logP$',size=30);\n",
    "    plt.ylabel('PDF',size=30);\n",
    "    plt.title('Posteriors JUMP',size=30);\n",
    "    plt.show()\n",
    "\n",
    "    lnhJ = np.amax(samplerJ.lnprobability[:,burn_Sj:].flat)\n",
    "else:\n",
    "    lnhJ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    AstEcl_corner(samplerJ,burn_Sj,int(mucorJ))  # flatD_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    AFD_style(samplerJ,burn_Sj,50,'J',int(mucorJ))  # flatD_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if Clear_key == True:\n",
    "# #     del flatD_J;\n",
    "#     samplerJ.reset();\n",
    "#     gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Combined Likelihood CDF's\n",
    "plt.figure(figsize=(12,6))\n",
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    plt.hist(samplerP.lnprobability[:,burn_Sp:].flat,100,normed=True,\n",
    "             color='g',histtype='stepfilled',cumulative=True,alpha=0.5);\n",
    "plt.hist(samplerB.lnprobability[:,burn_Sb:].flat,100,normed=True,\n",
    "         color='b',histtype='stepfilled',cumulative=True,alpha=0.5);\n",
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    plt.hist(samplerJ.lnprobability[:,burn_Sj:].flat,100,normed=True,\n",
    "             color='r',histtype='stepfilled',cumulative=True,alpha=0.5);\n",
    "plt.legend(('POLY','BLISS','JUMP'),bbox_to_anchor=(1.15,0.8))\n",
    "\n",
    "tech_cdfs = np.array([0,1.1])\n",
    "\n",
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    tech_actual_P = np.array([1,1])*data_post(real_P,T,Y_d,N,False,'N/A',posP,P_rP,'P')\n",
    "    plt.plot(tech_actual_P,tech_cdfs,'g--',lw=4)\n",
    "tech_actual_B = np.array([1,1])*data_post(real_B,T,Y_d,N,False,'N/A',posB,P_rB,'B')\n",
    "plt.plot(tech_actual_B,tech_cdfs,'b--',lw=4)\n",
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    tech_actual_J = np.array([1,1])*data_post(real_J,T,Y_d,N,False,'N/A',posJ,P_rJ,'J')\n",
    "    plt.plot(tech_actual_J,tech_cdfs,'r--',lw=4)\n",
    "tech_cdfs = np.array([0,1.1])\n",
    "\n",
    "plt.xlabel('$logP$',size=30);\n",
    "lnhALL = max(lnhP,lnhB,lnhJ)\n",
    "# plt.xlim([lnhALL-50,lnhALL+5])\n",
    "plt.ylabel('CDF',size=30);\n",
    "plt.ylim([0,1.1])\n",
    "plt.title('Posteriors',size=30);\n",
    "# plt.legend(('POLY','BLISS','JUMP'),bbox_to_anchor=(1.15,0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Extra Vizualization (& Saving Area)\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ast_true,'',Ecl_true,'',DCs_true,'',Cov_true,'',SigF_true\n",
    "\n",
    "# if Dump_key == True:\n",
    "#     np.save('EMCEE_PBJ_true',np.concatenate((Ast_true,Ecl_true,DCs_true,Kfl_true,Cov_true,SigF_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndimP,ndimB,ndimJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi-square and BIC values for best fit parameters\n",
    "if (Viz_key == True) and (yesdoP == True):\n",
    "    gPnum = np.argmax(samplerP.flatlnprobability)\n",
    "    gP_chisq = -2.0*(data_like(samplerP.flatchain[gPnum],T,Y_d,N,False,'N/A',posP,'P') +\n",
    "                     N*np.log(samplerP.flatchain[gPnum,-1]))\n",
    "    gP_bic = gP_chisq + ndimP*np.log(N)\n",
    "    print('P-type')\n",
    "    print('Chi-square: %.3f' % gP_chisq)\n",
    "    print('BIC: %.2f' % gP_bic)\n",
    "    # print(-2.0*(data_like(samplerP.flatchain[gPnum],T,Y_d,N,False,'N/A','P') +\n",
    "    #             N*np.log(samplerP.flatchain[gPnum,-1])) +\n",
    "    #       ndimP*np.log(N))\n",
    "    print('Params: %i' % ndimP)\n",
    "    print()\n",
    "\n",
    "gBnum = np.argmax(samplerB.flatlnprobability)\n",
    "gB_chisq = -2.0*(data_like(samplerB.flatchain[gBnum],T,Y_d,N,False,'N/A',posB,'B') +\n",
    "                 N*np.log(samplerB.flatchain[gBnum,-1]))\n",
    "gB_bic = gB_chisq + ndimJ*np.log(N)  # ndimJ considers knots to really be parameters\n",
    "print('B-type')\n",
    "print('Chi-square: %.3f' % gB_chisq)\n",
    "print('BIC: %.2f [maybe %.2f]' % (gB_bic,(gB_chisq + ndimB*np.log(N))))  # Showing 'better' BIC value too\n",
    "print('Params: %i (Real: %i)' % (ndimB,ndimJ))\n",
    "print()\n",
    "\n",
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    gJnum = np.argmax(samplerJ.flatlnprobability)\n",
    "    gJ_chisq = -2.0*(data_like(samplerJ.flatchain[gJnum],T,Y_d,N,False,'N/A',posJ,'J') +\n",
    "                     N*np.log(samplerJ.flatchain[gJnum,-1]))\n",
    "    gJ_bic = gJ_chisq + ndimJ*np.log(N)\n",
    "    print('J-type')\n",
    "    print('Chi-square: %.3f' % gJ_chisq)\n",
    "    print('BIC: %.2f' % gJ_bic)\n",
    "    print('Params: %i' % ndimJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if yesdoP == True:\n",
    "    ptls_P = np.percentile(mini_thinner(samplerP.chain,0,int(mucorP)),[16,50,84],axis=0)\n",
    "ptls_B = np.percentile(mini_thinner(samplerB.chain,0,int(mucorB)),[16,50,84],axis=0)\n",
    "if yesdoJ == True:\n",
    "    ptls_J = np.percentile(mini_thinner(samplerJ.chain,0,int(mucorJ)),[16,50,84],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ppp_xlims(cen,h_wd,s_d,scale):\n",
    "    if (h_wd > (scale*s_d)):\n",
    "        plt.xlim(cen - scale*s_d,cen + scale*s_d)\n",
    "    else:\n",
    "        plt.xlim(cen - 1.05*h_wd,cen + 1.05*h_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# %matplotlib inline\n",
    "# %matplotlib osx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roller = 20  # Bin factor for displaying Y_d below\n",
    "avg_bins_Yd = np.zeros(N/roller)\n",
    "\n",
    "for n in np.linspace(0,N-1,N)[::roller]:\n",
    "    avg_bins_Yd[int(n/roller)] = np.mean(Y_d[n:n+roller])\n",
    "    \n",
    "# plt.scatter(T[::roller],avg_bins_Yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def little_loopy_sing(data,sz,wid,viz,typ):  # Normally sz = 200 and wid = 5\n",
    "    yy = plt.gca().get_ylim()[1]*0.9\n",
    "    if typ == 'P':\n",
    "        plt.scatter(data[1],yy,s=sz,c='w',zorder=2,alpha=1.0)  # Dummy background\n",
    "        s1 = plt.scatter(data[1],yy,s=sz,c=(0,1,0),zorder=2,alpha=0.5)\n",
    "        p1 = plt.plot([data[0],data[2]],[yy,yy],lw=wid,c=(0,0.625,0),zorder=1,alpha=0.3)\n",
    "    elif typ == 'B':\n",
    "        plt.scatter(data[1],yy,s=sz,c='w',zorder=2,alpha=1.0)  # Dummy background\n",
    "        s2 = plt.scatter(data[1],yy,s=sz,c=(0,0,1),zorder=2,alpha=0.5)\n",
    "        p2 = plt.plot([data[0],data[2]],[yy,yy],lw=wid,c=(0,0,0.625),zorder=1,alpha=0.3)\n",
    "    elif typ == 'J':\n",
    "        plt.scatter(data[1],yy,s=sz,c='w',zorder=2,alpha=1.0)  # Dummy background\n",
    "        s3 = plt.scatter(data[1],yy,s=sz,c=(1,0,0),zorder=2,alpha=0.5)\n",
    "        p3 = plt.plot([data[0],data[2]],[yy,yy],lw=wid,c=(0.625,0,0),zorder=1,alpha=0.3)\n",
    "    \n",
    "#     p4 = plt.axvline(0.005,color=(0.25,0.125,0),linestyle='--',linewidth=1.5,zorder=0)\n",
    "    \n",
    "#     if viz == True:\n",
    "#         s1.set_label(r'$P$-type')\n",
    "#         s2.set_label(r'$B$-type')\n",
    "#         s3.set_label(r'$J$-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "secs_in_hr = 3600.0\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "# plt.subplot2grid((6,2),(3,0),rowspan=3,colspan=1)\n",
    "plt.subplot(211)\n",
    "# plt.scatter(T/secs_in_hr,Y_d/A_m,c='k',alpha=0.25)\n",
    "plt.plot(T/secs_in_hr,D_m,color=(1.0,0.5,0),lw=0.5)\n",
    "plt.plot(T/secs_in_hr,A_m,color=(0.25,0.125,0),lw=3,linestyle='--')\n",
    "# plt.xlim([l_t,h_t]);\n",
    "plt.xlim([0,6]);\n",
    "# plt.xlabel('Time (hr)',size='x-large');\n",
    "plt.gca().set_xticklabels([])\n",
    "# plt.xlabel('Time (hr)',size='x-large');\n",
    "# Dm_up,Dm_dw = np.amax(D_m),np.amin(D_m)\n",
    "# Dm_scl = Dm_up - Dm_dw\n",
    "# plt.ylim([Dm_dw - 0.2*Dm_scl,Dm_up + 0.2*Dm_scl])\n",
    "# plt.ylabel('$F(t)/A(t)$',size=30);\n",
    "plt.title('Light Curve',size='large');\n",
    "# plt.figtext(0.92,0.5,r'$\\Delta D = %.5f$' % ideal_Delta_D,size=30)\n",
    "plt.ylim(0.985,1.06)\n",
    "plt.locator_params(axis='y',nbins=8)\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "\n",
    "# plt.subplot2grid((6,2),(0,0),rowspan=3,colspan=1)\n",
    "plt.subplot(212)\n",
    "# plt.scatter(T/secs_in_hr,Y_d,c='w',alpha=0.3)\n",
    "plt.scatter(T[::roller]/secs_in_hr,avg_bins_Yd,c='k',s=50,alpha=0.2,zorder=1)\n",
    "plt.plot(T/secs_in_hr,Y,color=(0.625,0.3125,0),lw=0.5,zorder=0)\n",
    "# plt.plot(T,A_m,'g',lw=2,alpha=0.5)\n",
    "# plt.xlim([l_t,h_t]);\n",
    "plt.xlim([0,6]);\n",
    "plt.xlabel('Time (hr)',size='x-large');\n",
    "# plt.gca().set_xticklabels([])\n",
    "Ybin_up,Ybin_dw = np.amax(avg_bins_Yd),np.amin(avg_bins_Yd)\n",
    "Ybin_scl = Ybin_up - Ybin_dw\n",
    "plt.ylim([Ybin_dw - 0.1*Ybin_scl,Ybin_up + 0.1*Ybin_scl])\n",
    "# plt.ylabel('$F(t)$',size=30);\n",
    "# plt.title('Light Curve',size='large');\n",
    "# plt.figtext(0.92,0.5,r'$\\$_{e} = %.4f$' % significance_decl,size=30)\n",
    "plt.ylim(0.985,1.06)\n",
    "plt.locator_params(axis='y',nbins=8)\n",
    "\n",
    "plt.gcf().add_subplot(111)\n",
    "plt.gca().set_axis_bgcolor('none')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().tick_params(labelcolor='none',top='off',bottom='off',left='off',right='off')\n",
    "# plt.xlabel('Detector Amplitude / Eclipse Depth',size='x-large')\n",
    "plt.ylabel('Relative Flux',size='x-large',labelpad=20)\n",
    "\n",
    "plt.tight_layout(h_pad=2)\n",
    "plt.show()\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# secs_in_hr = 3600.0\n",
    "\n",
    "# plt.figure(figsize=(9,6))\n",
    "\n",
    "# # plt.subplot2grid((6,2),(0,1),rowspan=2,colspan=1)\n",
    "# plt.subplot(311)\n",
    "# plt.hist(mini_thinner(samplerP.chain,0,int(mucorP))[:,5],45,range=(0,0.015),normed=True,\n",
    "#                       color=(0,1,0),alpha=0.5)  # samplerP.chain[:,:,5].flat\n",
    "# # plt.hist(tfchnP[:,5],50,range=(0,0.012),normed=True,color=(0,1,0),alpha=0.5)\n",
    "# plt.axvline(Ecl_true[2],color=(0.25,0.125,0),linestyle='--',linewidth=3,zorder=1)\n",
    "# plt.title('MCMC Posteriors',size='large')\n",
    "# plt.ylabel(r'$P$-type',size='large')\n",
    "# plt.gca().yaxis.set_label_position('right')\n",
    "# plt.locator_params(axis='x',nbins=6)\n",
    "# plt.locator_params(axis='y',nbins=4)\n",
    "# plt.ylim([0,plt.gca().get_ylim()[1]*1.05])\n",
    "# plt.xlim(plt.gca().get_xlim())\n",
    "# # bar_add = ptls_P[:,5]  # 'Data_Info/10Se_1DDde_run2_PBJ_onlyEcl_ptls.npy'\n",
    "# little_loopy_sing(ptls_P[:,5],100,2.5,True,'P')\n",
    "# plt.xlim([0,0.015])\n",
    "\n",
    "# # plt.subplot2grid((6,2),(2,1),rowspan=2,colspan=1)\n",
    "# plt.subplot(312)\n",
    "# plt.hist(mini_thinner(samplerB.chain,0,int(mucorB))[:,5],150,range=(0,0.05),normed=True,\n",
    "#                       color=(0,0,1),alpha=0.5)  # samplerB.chain[:,:,5].flat\n",
    "# # plt.hist(tfchnB[:,5],150,range=(0,0.036),normed=True,color=(0,0,1),alpha=0.5)  # Adding range---for main figure\n",
    "# plt.axvline(Ecl_true[2],color=(0.25,0.125,0),linestyle='--',linewidth=3,zorder=1)\n",
    "# plt.ylabel(r'$B$-type',size='large')\n",
    "# plt.gca().yaxis.set_label_position('right')\n",
    "# plt.locator_params(axis='x',nbins=6)\n",
    "# plt.locator_params(axis='y',nbins=4)\n",
    "# plt.ylim([0,plt.gca().get_ylim()[1]*1.25])\n",
    "# plt.xlim(plt.gca().get_xlim())\n",
    "# little_loopy_sing(ptls_B[:,5],100,2.5,True,'B')\n",
    "# plt.xlim([0,0.015])  # By 3x bins and range, should make same bin sizes as other panels!\n",
    "\n",
    "# # plt.subplot2grid((6,2),(4,1),rowspan=2,colspan=1)\n",
    "# plt.subplot(313)\n",
    "# plt.hist(mini_thinner(samplerJ.chain,0,int(mucorJ))[:,5],45,range=(0,0.015),normed=True,\n",
    "#                       color=(1,0,0),alpha=0.5)  # samplerJ.chain[:,:,5].flat\n",
    "# # plt.hist(tfchnJ[:,5],50,range=(0,0.012),normed=True,color=(1,0,0),alpha=0.5)\n",
    "# plt.axvline(Ecl_true[2],color=(0.25,0.125,0),linestyle='--',linewidth=3,zorder=1)\n",
    "# plt.ylabel(r'$J$-type',size='large')\n",
    "# plt.gca().yaxis.set_label_position('right')\n",
    "# plt.xlabel('Eclipse Depth',size='x-large')\n",
    "# plt.locator_params(axis='x',nbins=6)\n",
    "# plt.locator_params(axis='y',nbins=4)\n",
    "# plt.ylim([0,plt.gca().get_ylim()[1]*1.2])\n",
    "# plt.xlim(plt.gca().get_xlim())\n",
    "# little_loopy_sing(ptls_J[:,5],100,2.5,True,'J')\n",
    "# plt.xlim([0,0.015])\n",
    "\n",
    "# plt.gcf().add_subplot(111)\n",
    "# plt.gca().set_axis_bgcolor('none')\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['bottom'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().tick_params(labelcolor='none',top='off',bottom='off',left='off',right='off')\n",
    "# # plt.xlabel('Detector Amplitude / Eclipse Depth',size='x-large')\n",
    "# plt.ylabel('Probability Density',size='x-large',labelpad=15)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "    \n",
    "# ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.sum(mini_thinner(samplerB.chain,0,int(mucorB))[:,5] > 0.015)/np.sum(mini_thinner(samplerB.chain,0,int(mucorB))[:,5] > -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def little_plots(low,up,n):\n",
    "#     plt.ylim([0,1])\n",
    "#     plt.yticks([])\n",
    "#     plt.xlim([low,up])\n",
    "#     plt.xticks(np.linspace(low,up,n),np.linspace(low,up,n))\n",
    "    \n",
    "# def little_loopy(data,sz,wid,viz):  # Normally sz = 200 and wid = 5\n",
    "#     s1 = plt.scatter(data[1],0.75,s=sz,c=(0,1,0),zorder=2)\n",
    "#     p1 = plt.plot([data[0],data[2]],[0.75,0.75],lw=wid,c=(0,0.625,0),zorder=1)\n",
    "\n",
    "#     s2 = plt.scatter(data[4],0.5,s=sz,c=(0,0,1),zorder=2)\n",
    "#     p2 = plt.plot([data[3],data[5]],[0.5,0.5],lw=wid,c=(0,0,0.625),zorder=1)\n",
    "    \n",
    "#     s3 = plt.scatter(data[7],0.25,s=sz,c=(1,0,0),zorder=2)\n",
    "#     p3 = plt.plot([data[6],data[8]],[0.25,0.25],lw=wid,c=(0.625,0,0),zorder=1)\n",
    "    \n",
    "#     p4 = plt.axvline(0.005,color=(0.25,0.125,0),linestyle='--',linewidth=1.5,zorder=0)\n",
    "    \n",
    "#     if viz == True:\n",
    "#         s1.set_label(r'$P$-type')\n",
    "#         s2.set_label(r'$B$-type')\n",
    "#         s3.set_label(r'$J$-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def extra_beta(data,btaP,btaB,btaJ,wid,alp):  # Normally wid = 5\n",
    "#     plt.plot([data[1] - btaP*(data[1]-data[0]),\n",
    "#               data[1] + btaP*(data[2]-data[1])],[0.75,0.75],lw=wid,c=(0,0.625,0),zorder=1,alpha=alp)\n",
    "\n",
    "#     plt.plot([data[4] - btaB*(data[4]-data[3]),\n",
    "#               data[4] + btaB*(data[5]-data[4])],[0.5,0.5],lw=wid,c=(0,0,0.625),zorder=1,alpha=alp)\n",
    "    \n",
    "#     plt.plot([data[7] - btaJ*(data[7]-data[6]),\n",
    "#               data[7] + btaJ*(data[8]-data[7])],[0.25,0.25],lw=wid,c=(0.625,0,0),zorder=1,alpha=alp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comparing B, J, 'Actual' Knots\n",
    "\n",
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    # Kmu_typeJ = np.mean(samplerJ.chain[:,burn_Sj::int(mucorJ),6:6+tot_goodK],axis=(0,1))\n",
    "    # Kstd_typeJ = np.std(samplerJ.chain[:,burn_Sj::int(mucorJ),6:6+tot_goodK],axis=(0,1))\n",
    "    Kmu_typeJ = np.mean(mini_thinner(samplerJ.chain,0,int(mucorJ))[:,6:6+tot_goodK],axis=0)\n",
    "    Kstd_typeJ = np.std(mini_thinner(samplerJ.chain,0,int(mucorJ))[:,6:6+tot_goodK],axis=0)\n",
    "\n",
    "    # tot_goodK = ndimJ - ndimB\n",
    "    # Kmu_typeB = np.mean(tf_K_repo_typeB,axis=0)\n",
    "    # Kstd_typeB = np.std(tf_K_repo_typeB,axis=0)\n",
    "    # Kmu_typeJ = np.mean(tfchnJ[:,6:6+tot_goodK],axis=0)\n",
    "    # Kstd_typeJ = np.std(tfchnJ[:,6:6+tot_goodK],axis=0)\n",
    "\n",
    "    # Best set of BLISS knots\n",
    "    steps_in_mychain = samplerB.chain.shape[1]  # Usually 10000, sometimes 5000\n",
    "    gBnum = np.argmax(samplerB.lnprobability)\n",
    "    best_b_step = (gBnum % steps_in_mychain)\n",
    "    best_b_walk = (gBnum - best_b_step)/steps_in_mychain\n",
    "    best_K_typeB = K_repo_typeB[best_b_walk,best_b_step,:]\n",
    "\n",
    "    i_off = 0.0\n",
    "    a_lev = 0.5\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for i in np.linspace(0,tot_goodK-1,tot_goodK):\n",
    "        plt.scatter(i-i_off,Kmu_typeB[i] - Kfl_true[i],s=50,c='b',zorder=2)\n",
    "        plt.scatter(i-i_off,best_K_typeB[i] - Kfl_true[i],marker='*',s=100,c='c',zorder=2)\n",
    "        plt.scatter(i+i_off,Kmu_typeJ[i] - Kfl_true[i],s=50,c='r',zorder=2)\n",
    "        if i == 0:\n",
    "            plt.plot(i,0,lw=3,ls='--',c='m',zorder=2)\n",
    "            plt.legend(('True',r'$B$-type',r'Best $B$-type',r'$J$-type'),loc='upper right',\n",
    "                      fontsize='small')\n",
    "        plt.plot(np.array([i-i_off,i-i_off]),np.array([Kmu_typeB[i] - Kstd_typeB[i] - Kfl_true[i],\n",
    "                                           Kmu_typeB[i] + Kstd_typeB[i] - Kfl_true[i]]),\n",
    "                 lw=3,c='b',alpha=a_lev,zorder=1)\n",
    "        plt.plot(np.array([i+i_off,i+i_off]),np.array([Kmu_typeJ[i] - Kstd_typeJ[i] - Kfl_true[i],\n",
    "                                           Kmu_typeJ[i] + Kstd_typeJ[i] - Kfl_true[i]]),\n",
    "                 lw=3,c='r',alpha=a_lev,zorder=1)\n",
    "    plt.plot(np.array([-1,tot_goodK]),np.array([0,0]),lw=3,c='m',ls='--',zorder=1)\n",
    "    plt.fill_between(np.array([-1,tot_goodK]),np.amax(Kfl_true) - np.mean(Kfl_true),\n",
    "                     np.amin(Kfl_true) - np.mean(Kfl_true),color='m',alpha=a_lev)\n",
    "    plt.xlim([-1,tot_goodK]);\n",
    "    plt.ylim([-0.05,0.05]);\n",
    "    plt.xlabel('Knot (ID)',size='x-large');\n",
    "    plt.ylabel('Discrepancy',size='x-large');\n",
    "    plt.title('Knot Comparison',size='large');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (Viz_key == True) and (yesdoJ == True):\n",
    "    # dum1_Dxy_Solo,dum2_Dxy_Solo = np.zeros((10,10)),np.zeros((10,10))\n",
    "    dum1_Dxy_Solo,dum2_Dxy_Solo = np.zeros(Dxy_Solo.shape),np.zeros(Dxy_Solo.shape)\n",
    "\n",
    "    bestmcmcK_B = map_flux_jumped(dum1_Dxy_Solo,(best_K_typeB - Kfl_true)/(np.amax(Kfl_true) - np.amin(Kfl_true)))\n",
    "    ratioSTDknots_BJ = map_flux_jumped(dum2_Dxy_Solo,Kstd_typeB/Kstd_typeJ)\n",
    "\n",
    "    # fB_avg = map_flux_avgQuick(Y_d,A_m,xNt_B_lin)\n",
    "    # F_avg = map_flux_jumped(Dxy_Solo,Kfl_true)  # Uniform [Y,X] solved the problem! Will JUMP-sampler run better...?\n",
    "    # minviz = np.amin(F_avg[tmask_goodBKT])\n",
    "    # maxviz = np.amax(F_avg[tmask_goodBKT])\n",
    "\n",
    "    # plt.figure(figsize=(12,6))\n",
    "    plt.figure(figsize=(6,6))\n",
    "\n",
    "    # # plt.subplot2grid((2,6),(0,2),rowspan=2,colspan=2)\n",
    "    # plt.subplot(121)\n",
    "    # easy_tic = np.linspace(-1.5,1.5,7)\n",
    "    # extra_bestmcmcK_B = bestmcmcK_B\n",
    "    # extra_bestmcmcK_B[tmask_goodBKT == False] = np.nan\n",
    "    # m_bestmcmc = plt.imshow(extra_bestmcmcK_B,interpolation='hermite',origin='lower',\n",
    "    #                       extent=[x_Knots[0],x_Knots[-1],y_Knots[0],y_Knots[-1]],\n",
    "    #                       cmap=cm.coolwarm,vmin=-1.5,vmax=1.5)\n",
    "    # m_bestmcmc.cmap.set_bad(color='w',alpha=0.0)\n",
    "    # plt.colorbar(m_bestmcmc,extend='both',label=r'(BLISS - True) / $\\Delta$ True',ticks=easy_tic,shrink=0.75)\n",
    "    # plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "    # # plt.xticks([])\n",
    "    # plt.xlabel('Pixel x',size='x-large');\n",
    "    # plt.ylabel('Pixel y',size='x-large');\n",
    "    # # plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "    # plt.title(r'Best $B$-type vs True Map',size='large')\n",
    "    # plt.locator_params(axis='x',nbins=6)\n",
    "    # plt.locator_params(axis='y',nbins=6)\n",
    "\n",
    "    # # plt.subplot2grid((2,6),(0,4),rowspan=2,colspan=2)\n",
    "    # plt.subplot(122)\n",
    "    extra_ratioSTDknots_BJ = ratioSTDknots_BJ\n",
    "    extra_ratioSTDknots_BJ[tmask_goodBKT == False] = np.nan  # So bad knots fall outside the color range.\n",
    "\n",
    "    m_ratioBJ = plt.imshow(extra_ratioSTDknots_BJ,interpolation='hermite',origin='lower',\n",
    "               extent=ext_bounds,cmap=cm.plasma)  #,vmin=0.2,vmax=0.81)  # cmap=cm.inferno\n",
    "    # m_ratioBJ.cmap.set_bad(color='w',alpha=1.0)\n",
    "    plt.colorbar(m_ratioBJ,extend='neither',\n",
    "                 label='Ratio of Standard Deviations',ticks=np.linspace(0.0,2.0,11),shrink=0.75)  # label='STD[ $B$-type ] / STD[ $J$-type ]'\n",
    "    plt.gca().set_aspect((x_Knots[-1]-x_Knots[0])/(y_Knots[-1]-y_Knots[0]))\n",
    "    plt.xlabel('Pixel x',size='x-large');\n",
    "    plt.ylabel('Pixel y',size='x-large');\n",
    "    # plt.scatter(xKmesh,yKmesh,color=(1,1,1),marker='x',alpha=0)\n",
    "    plt.title(r'$B$-type / $J$-type Knots',size='large')\n",
    "    plt.locator_params(axis='x',nbins=6)\n",
    "    plt.locator_params(axis='y',nbins=6)\n",
    "\n",
    "    # plt.tight_layout(w_pad=3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Misc. Area\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # # RELOAD AREA (Everything) # # #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('chisq')\n",
    "# if yesdoJ == True:\n",
    "#     print(np.around((gP_chisq,gB_chisq,gJ_chisq),1))\n",
    "# else:\n",
    "#     print(np.around((gP_chisq,gB_chisq),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('bic')\n",
    "# if yesdoJ == True:\n",
    "#     print(np.around((gP_bic,gB_bic,gJ_bic),1)),print(np.around(gB_bicLow,1))\n",
    "# else:\n",
    "#     print(np.around((gP_bic,gB_bic),1)),print(np.around(gB_bicLow,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # # # Beta Factors\n",
    "\n",
    "from numpy.lib import stride_tricks\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_model_maker(natlogprob,mcmc_chain,mcmc_steps):\n",
    "    best_num = np.argmax(natlogprob)\n",
    "    best_step = (best_num % mcmc_steps)\n",
    "    best_walker = (best_num - best_step)/mcmc_steps\n",
    "    theta = mcmc_chain[best_walker,best_step]\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_resids_maker(natlogprob,mcmc_chain,mcmc_steps,t_sing,y_d,n_data,run_type):\n",
    "    theta = best_model_maker(natlogprob,mcmc_chain,mcmc_steps) # theta can have: 3A, 3E, #C, #K, 3Cov, 1SF\n",
    "    \n",
    "    astro = theta[:3]\n",
    "    ecl = theta[3:6]\n",
    "    y_ast = perf_astro_model(t_sing[0],t_sing[-1],t_sing,astro,ecl)\n",
    "    if Cov_key == True:\n",
    "        sx,sy,rho = theta[-3+SF_i],theta[-2+SF_i],theta[-1+SF_i]\n",
    "    \n",
    "    if run_type == 'P':\n",
    "        cn_out_Vector[:polyO_out] = theta[6:6+polyO_out]\n",
    "        cn_out_Vector[polyO_out+1:] = theta[6+polyO_out:6+Cn_out]\n",
    "        C_UTout[UTout_i] = cn_out_Vector\n",
    "        if Cov_key == True:\n",
    "            if FastRYX_key == True:\n",
    "                d_model = sigxy_DM_alt(C_UTout,xKmesh,yKmesh,sx,sy,rho,DProb_LookTab,n_data)\n",
    "            else:\n",
    "                d_model = sigxy_detect_model(C_UTout,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,n_data)\n",
    "        else:\n",
    "            d_model = perf_detect_model(xNt_vals,yNt_vals,C_UTout,n_data)\n",
    "    else:\n",
    "        if run_type == 'B':\n",
    "            if Cov_key == True:\n",
    "                if FastRYX_key == True:\n",
    "                    sens_map = map_FE_alt(y_d,y_ast,sx,sy,rho,DProb_LookTab)\n",
    "                else:\n",
    "                    sens_map = map_flux_eval(y_d,y_ast,mask_EtoK,xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho)\n",
    "            else:\n",
    "                sens_map = map_flux_avgQuick(y_d,y_ast,xNt_B_lin)\n",
    "            d_model = bliss_meth(n_data,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "        elif run_type == 'J':\n",
    "            f_knots = theta[6:6+tot_goodK]\n",
    "            if Cov_key == True:\n",
    "                if FastRYX_key == True:\n",
    "                    d_model = sigxy_EVM_alt(Dxy_Solo,f_knots,sx,sy,rho,DProb_LookTab,n_data)\n",
    "                else:\n",
    "                    d_model = sigxy_eval_map(Dxy_Solo,f_knots,f_bliss_Egrid,f_bliss_Evect,xoE,yoE,\n",
    "                                             xEmesh_n,yEmesh_n,xNt_vals,yNt_vals,sx,sy,rho,n_data)\n",
    "            else:\n",
    "                sens_map = map_flux_jumped(Dxy_Solo,f_knots)\n",
    "                d_model = bliss_meth(n_data,flux_bliss,sens_map,xNt_vals,yNt_vals)\n",
    "    \n",
    "    resids = y_d - (y_ast*d_model)\n",
    "\n",
    "#     if SigF_key == True:\n",
    "#         sF = theta[-1:]\n",
    "#         lglike = -n_data*np.log(sF) - 0.5*np.sum((numer/sF)**2.0)  # Corrected: include \"n_data\"\n",
    "#     else:\n",
    "#         lglike = -n_data*np.log(SigF_true) - 0.5*np.sum((numer/SigF_true)**2.0)\n",
    "        \n",
    "    return y_ast*d_model,resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling(vec,window):\n",
    "    new_dim = ((vec.size - window + 1),window)\n",
    "    new_bytes = (vec.itemsize,vec.itemsize)\n",
    "    return stride_tricks.as_strided(vec,shape=new_dim,strides=new_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding which bin sizes will have even numbers of data points\n",
    "\n",
    "all_divisors = np.where((N*np.ones(N) % np.linspace(1,N,N)) == 0)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poisson_scatter(sigf,divs):\n",
    "    ideal_scat = sigf/(divs**0.5)  # Poisson limit for each bin size\n",
    "    return ideal_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta_plotter(resids,divs):\n",
    "    binned_scat = np.zeros(divs.shape)\n",
    "    for i in np.linspace(1,len(divs),len(divs)):\n",
    "        if i == 1:\n",
    "            binned_scat[i-1] = np.mean(resids**2.0)**0.5\n",
    "        else:\n",
    "            chunks = rolling(resids,divs[i-1])[::divs[i-1]]  # Only taking unique bins\n",
    "            binned_scat[i-1] = np.mean(np.mean(chunks,axis=1)**2.0)**0.5\n",
    "    return binned_scat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta_visual(mybins,myideal,myuncert,tit,mycolor,n_data):\n",
    "    plt.plot(mybins,myuncert,c=mycolor)\n",
    "    plt.plot(mybins,myideal,'k',ls='--')\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "    plt.gca().set_yscale('log')\n",
    "    plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "    plt.xlim([1,n_data])\n",
    "    plt.xlabel('Bin Size',size='large')\n",
    "    plt.ylim([np.amin(myuncert)*0.75,np.amax(myuncert)*1.3])\n",
    "    plt.ylabel('RMS Scatter',size='large')\n",
    "    this_beta = np.amax(myuncert/myideal)\n",
    "    plt.title(tit+r' $\\beta$ = %.3f' % this_beta,size='large')\n",
    "    if this_beta >= 1.0:\n",
    "        return this_beta\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if yesdoP == True:\n",
    "    chain_sizesP = samplerP.chain.shape[1]\n",
    "    bestfit_model_P,bestfit_resids_P = best_resids_maker(samplerP.lnprobability,samplerP.chain,\n",
    "                                                         chain_sizesP,T,Y_d,N,'P')\n",
    "    bins_uncert_P = beta_plotter(bestfit_resids_P,all_divisors)\n",
    "\n",
    "chain_sizesB = samplerB.chain.shape[1]\n",
    "bestfit_model_B,bestfit_resids_B = best_resids_maker(samplerB.lnprobability,samplerB.chain,\n",
    "                                                     chain_sizesB,T,Y_d,N,'B')\n",
    "bins_uncert_B = beta_plotter(bestfit_resids_B,all_divisors)\n",
    "\n",
    "if yesdoJ == True:\n",
    "    chain_sizesJ = samplerJ.chain.shape[1]\n",
    "    bestfit_model_J,bestfit_resids_J = best_resids_maker(samplerJ.lnprobability,samplerJ.chain,\n",
    "                                                         chain_sizesJ,T,Y_d,N,'J')\n",
    "    bins_uncert_J = beta_plotter(bestfit_resids_J,all_divisors)\n",
    "\n",
    "poiss_uncert = poisson_scatter(SigF_true,all_divisors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "if yesdoP == True:\n",
    "    plt.subplot(131)\n",
    "    ppp_Beta = beta_visual(all_divisors,poiss_uncert,bins_uncert_P,r'$P$-type','g',N)\n",
    "else:\n",
    "    ppp_Beta = 1.0\n",
    "\n",
    "plt.subplot(132)\n",
    "bbb_Beta = beta_visual(all_divisors,poiss_uncert,bins_uncert_B,r'$B$-type','b',N)\n",
    "\n",
    "if yesdoJ == True:\n",
    "    plt.subplot(133)\n",
    "    jjj_Beta = beta_visual(all_divisors,poiss_uncert,bins_uncert_J,r'$J$-type','r',N)\n",
    "else:\n",
    "    jjj_Beta = 1.0\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # SAVES WHEN ORIGINALLY GENERATING\n",
    "## file_Name = 'Data_Info/NULL_NULL_NULL_'  # Description of dataset\n",
    "\n",
    "## np.save(file_Name+'EMCEE_PBJ_priors',np.concatenate((P_rP,P_rB,P_rJ),axis=1))\n",
    "\n",
    "## np.save(file_Name+'EMCEE_PBJ_true',np.concatenate((Ast_true,Ecl_true,DCs_true,DCs_fit_true,\n",
    "##                                                    Kfl_true,Cov_true,SigF_true)))\n",
    "## np.save(file_Name+'EMCEE_PBJ_data',np.vstack((T,A_m,D_m,Y,Y_d,xNt_vals,yNt_vals,xNt_perf,yNt_perf)))\n",
    "## np.save(file_Name+'EMCEE_PBJ_polyOCn',np.array([polyO_in,Cn_in,polyO_out,Cn_out]))\n",
    "\n",
    "## if Brown_key == True:\n",
    "##     np.save(file_Name+'EMCEE_PBJ_brownsignal',Bro_noi)\n",
    "    \n",
    "## if want_noisyM_key == True:\n",
    "##     np.save(file_Name+'EMCEE_PBJ_splinyMnoise',Master_pixNoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Sound to play after finishing, if you're running to the end of the notebook.\n",
    "# Audio('INSERT YOUR FILEPATH FOR SOME SOUND/SONG HERE',autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.std(bestfit_resids_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptls_B[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
